<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Observation Models · GaussianMarkovRandomFields.jl</title><meta name="title" content="Observation Models · GaussianMarkovRandomFields.jl"/><meta property="og:title" content="Observation Models · GaussianMarkovRandomFields.jl"/><meta property="twitter:title" content="Observation Models · GaussianMarkovRandomFields.jl"/><meta name="description" content="Documentation for GaussianMarkovRandomFields.jl."/><meta property="og:description" content="Documentation for GaussianMarkovRandomFields.jl."/><meta property="twitter:description" content="Documentation for GaussianMarkovRandomFields.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/citations.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="GaussianMarkovRandomFields.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">GaussianMarkovRandomFields.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/">Overview</a></li><li><a class="tocitem" href="../../tutorials/autoregressive_models/">Building autoregressive models</a></li><li><a class="tocitem" href="../../tutorials/spatial_modelling_spdes/">Spatial Modelling with SPDEs</a></li><li><a class="tocitem" href="../../tutorials/spatiotemporal_modelling/">Spatiotemporal Modelling with SPDEs</a></li><li><a class="tocitem" href="../../tutorials/boundary_conditions/">Boundary Conditions for SPDEs</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">API Reference</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../gmrfs/">GMRFs</a></li><li><a class="tocitem" href="../latent_models/">Latent Models</a></li><li class="is-active"><a class="tocitem" href>Observation Models</a><ul class="internal"><li><a class="tocitem" href="#Core-Concepts"><span>Core Concepts</span></a></li><li><a class="tocitem" href="#Exponential-Family-Models"><span>Exponential Family Models</span></a></li><li><a class="tocitem" href="#Custom-Observation-Models"><span>Custom Observation Models</span></a></li><li><a class="tocitem" href="#Advanced-Features"><span>Advanced Features</span></a></li><li><a class="tocitem" href="#API-Reference"><span>API Reference</span></a></li></ul></li><li><a class="tocitem" href="../gaussian_approximation/">Gaussian Approximation</a></li><li><a class="tocitem" href="../hard_constraints/">Hard Constraints</a></li><li><a class="tocitem" href="../spdes/">SPDEs</a></li><li><a class="tocitem" href="../discretizations/">Discretizations</a></li><li><a class="tocitem" href="../meshes/">Meshes</a></li><li><a class="tocitem" href="../plotting/">Plotting</a></li><li><a class="tocitem" href="../solvers/">Solvers</a></li><li><a class="tocitem" href="../autoregressive/">Autoregressive Models</a></li><li><a class="tocitem" href="../linear_maps/">Linear maps</a></li><li><a class="tocitem" href="../preconditioners/">Preconditioners</a></li></ul></li><li><a class="tocitem" href="../../bibliography/">Bibliography</a></li><li><input class="collapse-toggle" id="menuitem-5" type="checkbox"/><label class="tocitem" for="menuitem-5"><span class="docs-label">Developer Documentation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../dev-docs/">Overview</a></li><li><a class="tocitem" href="../../dev-docs/solvers/">Solvers</a></li><li><a class="tocitem" href="../../dev-docs/spdes/">SPDEs</a></li><li><a class="tocitem" href="../../dev-docs/discretizations/">Discretizations</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">API Reference</a></li><li class="is-active"><a href>Observation Models</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Observation Models</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/main/docs/src/reference/observation_models.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Observation-Models"><a class="docs-heading-anchor" href="#Observation-Models">Observation Models</a><a id="Observation-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Observation-Models" title="Permalink"></a></h1><p>Observation models define the relationship between observations <code>y</code> and the latent GMRF field <code>x</code>, typically through likelihood functions. They enable Bayesian inference by connecting your data to the underlying Gaussian process through flexible probabilistic models.</p><p>GaussianMarkovRandomFields.jl implements observation models using a <strong>factory pattern</strong> that separates model configuration from materialized evaluation instances. This design provides major performance benefits in optimization loops and cleaner automatic differentiation boundaries.</p><h2 id="Core-Concepts"><a class="docs-heading-anchor" href="#Core-Concepts">Core Concepts</a><a id="Core-Concepts-1"></a><a class="docs-heading-anchor-permalink" href="#Core-Concepts" title="Permalink"></a></h2><h3 id="The-Factory-Pattern"><a class="docs-heading-anchor" href="#The-Factory-Pattern">The Factory Pattern</a><a id="The-Factory-Pattern-1"></a><a class="docs-heading-anchor-permalink" href="#The-Factory-Pattern" title="Permalink"></a></h3><p>Observation models follow a two-stage pattern:</p><ol><li><strong>ObservationModel</strong>: A factory that defines the model structure and hyperparameters</li><li><strong>ObservationLikelihood</strong>: A materialized instance with specific data and hyperparameters for fast evaluation</li></ol><pre><code class="language-julia hljs"># Step 1: Configure observation model (factory)
obs_model = ExponentialFamily(Normal)

# Step 2: Materialize with data and hyperparameters  
obs_lik = obs_model(y; σ=1.2)

# Step 3: Fast evaluation in hot loops
ll = loglik(x, obs_lik)      # Only x argument needed!
grad = loggrad(x, obs_lik)   # Fast x-only evaluation
hess = loghessian(x, obs_lik)</code></pre><p>This pattern eliminates the need to repeatedly pass data and hyperparameters, providing significant performance benefits in optimization and sampling algorithms.</p><h3 id="Evaluation-Interface"><a class="docs-heading-anchor" href="#Evaluation-Interface">Evaluation Interface</a><a id="Evaluation-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluation-Interface" title="Permalink"></a></h3><p>All materialized observation likelihoods support a common interface:</p><ul><li><code>loglik(x, obs_lik)</code>: Evaluate log-likelihood </li><li><code>loggrad(x, obs_lik)</code>: Compute gradient with respect to latent field</li><li><code>loghessian(x, obs_lik)</code>: Compute Hessian matrix</li></ul><h2 id="Exponential-Family-Models"><a class="docs-heading-anchor" href="#Exponential-Family-Models">Exponential Family Models</a><a id="Exponential-Family-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Exponential-Family-Models" title="Permalink"></a></h2><p>The most common observation models are exponential family distributions connected to the latent field through link functions.</p><h3 id="Basic-Usage"><a class="docs-heading-anchor" href="#Basic-Usage">Basic Usage</a><a id="Basic-Usage-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-Usage" title="Permalink"></a></h3><pre><code class="language-julia hljs">using GaussianMarkovRandomFields
using Distributions

# Poisson model for count data (canonical LogLink)
poisson_model = ExponentialFamily(Poisson)
x = [1.0, 2.0]  # Latent field (log-intensity due to LogLink)
y = [2, 7]      # Count observations
obs_lik = poisson_model(y)
ll = loglik(x, obs_lik)

# Normal model for continuous data (canonical IdentityLink)
normal_model = ExponentialFamily(Normal)
x = [1.5, 2.3]  # Latent field (direct mean due to IdentityLink)
y = [1.2, 2.8]  # Continuous observations
obs_lik = normal_model(y; σ=0.5)  # Normal requires σ hyperparameter
ll = loglik(x, obs_lik)

# Bernoulli model for binary data (canonical LogitLink)
bernoulli_model = ExponentialFamily(Bernoulli)
x = [0.0, 1.5]  # Latent field (logit-probability due to LogitLink)
y = [0, 1]      # Binary observations
obs_lik = bernoulli_model(y)
ll = loglik(x, obs_lik)</code></pre><h3 id="Supported-Distributions-and-Links"><a class="docs-heading-anchor" href="#Supported-Distributions-and-Links">Supported Distributions and Links</a><a id="Supported-Distributions-and-Links-1"></a><a class="docs-heading-anchor-permalink" href="#Supported-Distributions-and-Links" title="Permalink"></a></h3><table><tr><th style="text-align: right">Distribution</th><th style="text-align: right">Canonical Link</th><th style="text-align: right">Alternative Links</th><th style="text-align: right">Hyperparameters</th></tr><tr><td style="text-align: right">Normal</td><td style="text-align: right">IdentityLink</td><td style="text-align: right">LogLink</td><td style="text-align: right">σ (std. dev.)</td></tr><tr><td style="text-align: right">Poisson</td><td style="text-align: right">LogLink</td><td style="text-align: right">IdentityLink</td><td style="text-align: right">none</td></tr><tr><td style="text-align: right">Bernoulli</td><td style="text-align: right">LogitLink</td><td style="text-align: right">LogLink</td><td style="text-align: right">none</td></tr><tr><td style="text-align: right">Binomial</td><td style="text-align: right">LogitLink</td><td style="text-align: right">IdentityLink</td><td style="text-align: right">none*</td></tr></table><p>*For Binomial, the number of trials is provided through the data structure <code>BinomialObservations</code>, not as a hyperparameter.</p><h3 id="Custom-Link-Functions"><a class="docs-heading-anchor" href="#Custom-Link-Functions">Custom Link Functions</a><a id="Custom-Link-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-Link-Functions" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Non-canonical link function
poisson_identity = ExponentialFamily(Poisson, IdentityLink())
# Note: Requires positive latent field values for valid Poisson intensities</code></pre><h2 id="Custom-Observation-Models"><a class="docs-heading-anchor" href="#Custom-Observation-Models">Custom Observation Models</a><a id="Custom-Observation-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-Observation-Models" title="Permalink"></a></h2><p>For models not covered by exponential families, you can define custom log-likelihood functions using automatic differentiation.</p><h3 id="Basic-AutoDiff-Models"><a class="docs-heading-anchor" href="#Basic-AutoDiff-Models">Basic AutoDiff Models</a><a id="Basic-AutoDiff-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Basic-AutoDiff-Models" title="Permalink"></a></h3><pre><code class="language-julia hljs"># Define custom log-likelihood function
function custom_loglik(x; y=[1.0, 2.0], σ=1.0)
    μ = sin.(x)  # Custom transformation
    return -0.5 * sum((y .- μ).^2) / σ^2 - length(y) * log(σ)
end

# Create observation model
obs_model = AutoDiffObservationModel(custom_loglik; n_latent=2, hyperparams=(:y, :σ))

# Materialize with data
obs_lik = obs_model(y=[1.2, 1.8], σ=0.5)

# Use normally - gradients and Hessians computed automatically!
x = [0.5, 1.0]
ll = loglik(x, obs_lik)
grad = loggrad(x, obs_lik)    # Automatic differentiation
hess = loghessian(x, obs_lik) # Potentially sparse!</code></pre><h3 id="Automatic-Differentiation-Requirements"><a class="docs-heading-anchor" href="#Automatic-Differentiation-Requirements">Automatic Differentiation Requirements</a><a id="Automatic-Differentiation-Requirements-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation-Requirements" title="Permalink"></a></h3><p>AutoDiff observation models require an automatic differentiation backend. We support and recommend the following backends in order of preference:</p><ol><li><strong>Enzyme.jl</strong> (recommended for performance)</li><li><strong>Mooncake.jl</strong> (good balance of performance and compatibility)</li><li><strong>Zygote.jl</strong> (reliable fallback)</li><li><strong>ForwardDiff.jl</strong> (for small problems)</li></ol><pre><code class="language-julia hljs"># Load an AD backend (required for AutoDiffObservationModel)
using Enzyme  # Recommended

# Or use another supported backend:
# using Mooncake
# using Zygote
# using ForwardDiff

# Now you can use AutoDiff models
obs_model = AutoDiffObservationModel(my_loglik; n_latent=10)
obs_lik = obs_model(y=data)
grad = loggrad(x, obs_lik)  # Uses your loaded AD backend</code></pre><h3 id="Sparse-Hessian-Computation"><a class="docs-heading-anchor" href="#Sparse-Hessian-Computation">Sparse Hessian Computation</a><a id="Sparse-Hessian-Computation-1"></a><a class="docs-heading-anchor-permalink" href="#Sparse-Hessian-Computation" title="Permalink"></a></h3><p>AutoDiff observation models can automatically detect and exploit sparsity in Hessian matrices using our package extensions. This requires loading both an AD backend and additional sparsity packages:</p><pre><code class="language-julia hljs"># Load AD backend + sparse AD packages
using Enzyme  # Or your preferred AD backend
using SparseConnectivityTracer, SparseMatrixColorings

# The package extension is automatically activated
obs_model = AutoDiffObservationModel(my_loglik; n_latent=100)
obs_lik = obs_model(y=data)

# Hessian computation now automatically:
# - Detects sparsity pattern using TracerSparsityDetector  
# - Uses greedy coloring for efficient computation
# - Returns sparse matrix when beneficial
hess = loghessian(x, obs_lik)  # May be sparse!</code></pre><p>The sparse Hessian features provide dramatic performance improvements for large-scale problems with structured sparsity.</p><h2 id="Advanced-Features"><a class="docs-heading-anchor" href="#Advanced-Features">Advanced Features</a><a id="Advanced-Features-1"></a><a class="docs-heading-anchor-permalink" href="#Advanced-Features" title="Permalink"></a></h2><h3 id="Linear-Transformations-and-Design-Matrices"><a class="docs-heading-anchor" href="#Linear-Transformations-and-Design-Matrices">Linear Transformations and Design Matrices</a><a id="Linear-Transformations-and-Design-Matrices-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-Transformations-and-Design-Matrices" title="Permalink"></a></h3><p>For GLM-style modeling where observations are related to linear combinations of latent field components:</p><pre><code class="language-julia hljs"># Design matrix mapping latent field to linear predictors
# Rows = observations, Columns = latent components
A = [1.0  20.0  1.0  0.0;   # obs 1: intercept + temp + group1
     1.0  25.0  1.0  0.0;   # obs 2: intercept + temp + group1  
     1.0  30.0  0.0  1.0]   # obs 3: intercept + temp + group2

base_model = ExponentialFamily(Poisson)  # LogLink by default
obs_model = LinearlyTransformedObservationModel(base_model, A)

# Latent field now includes all components: [β₀, β₁, u₁, u₂]
x_full = [2.0, 0.1, -0.5, 0.3]  # intercept, slope, group effects
obs_lik = obs_model(y)
ll = loglik(x_full, obs_lik)  # Chain rule applied automatically</code></pre><h3 id="Binomial-Observations"><a class="docs-heading-anchor" href="#Binomial-Observations">Binomial Observations</a><a id="Binomial-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Binomial-Observations" title="Permalink"></a></h3><p>For binomial data, use the <code>BinomialObservations</code> utility:</p><pre><code class="language-julia hljs"># Create binomial observations with successes and trials
y = BinomialObservations([3, 1, 4], [5, 8, 6])  # (successes, trials) pairs

# Use with Binomial model
binomial_model = ExponentialFamily(Binomial) 
obs_lik = binomial_model(y)

# Access components
successes(y)  # [3, 1, 4]
trials(y)     # [5, 8, 6]
y[1]          # (3, 5) - tuple access</code></pre><h3 id="Composite-Observations"><a class="docs-heading-anchor" href="#Composite-Observations">Composite Observations</a><a id="Composite-Observations-1"></a><a class="docs-heading-anchor-permalink" href="#Composite-Observations" title="Permalink"></a></h3><p>For multiple observation types in a single model:</p><pre><code class="language-julia hljs"># Multiple observation vectors
count_data = [1, 3, 0, 2]
binary_data = [0, 1, 1, 0]
obs = CompositeObservations(count_data, binary_data)

# Corresponding models for each observation type
poisson_model = ExponentialFamily(Poisson)
bernoulli_model = ExponentialFamily(Bernoulli) 
composite_model = CompositeObservationModel(poisson_model, bernoulli_model)

obs_lik = composite_model(obs)
# Latent field x now corresponds to concatenated observations
ll = loglik(x, obs_lik)</code></pre><h2 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h2><h3 id="Core-Types-and-Interface"><a class="docs-heading-anchor" href="#Core-Types-and-Interface">Core Types and Interface</a><a id="Core-Types-and-Interface-1"></a><a class="docs-heading-anchor-permalink" href="#Core-Types-and-Interface" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.ObservationModel" href="#GaussianMarkovRandomFields.ObservationModel"><code>GaussianMarkovRandomFields.ObservationModel</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ObservationModel</code></pre><p>Abstract base type for all observation models for GMRFs.</p><p>An observation model defines the relationship between observations <code>y</code> and the latent field <code>x</code>, typically through a likelihood function. ObservationModel types serve as factories for creating ObservationLikelihood instances via callable syntax.</p><p><strong>Usage Pattern</strong></p><pre><code class="language-julia hljs"># Step 1: Create observation model (factory)
obs_model = ExponentialFamily(Normal)

# Step 2: Materialize with data and hyperparameters
obs_lik = obs_model(y; σ=1.2)  # Creates ObservationLikelihood

# Step 3: Use materialized likelihood in hot loops
ll = loglik(x, obs_lik)  # Fast x-only evaluation</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.ObservationLikelihood"><code>ObservationLikelihood</code></a>, <a href="#GaussianMarkovRandomFields.ExponentialFamily"><code>ExponentialFamily</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/observation_model.jl#L5-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.ObservationLikelihood" href="#GaussianMarkovRandomFields.ObservationLikelihood"><code>GaussianMarkovRandomFields.ObservationLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ObservationLikelihood</code></pre><p>Abstract base type for materialized observation likelihoods.</p><p>Observation likelihoods are created by materializing an observation model with specific hyperparameters θ and observed data y. They provide efficient evaluation methods that  only depend on the latent field x, eliminating the need to repeatedly pass θ and y.</p><p>This design provides major performance benefits in optimization loops and cleaner  automatic differentiation boundaries.</p><p><strong>Usage Pattern</strong></p><pre><code class="language-julia hljs"># Step 1: Configure observation model (factory)
obs_model = ExponentialFamily(Normal)

# Step 2: Materialize with data and hyperparameters  
obs_lik = obs_model(y; σ=1.2)

# Step 3: Fast evaluation in hot loops
ll = loglik(x, obs_lik)      # Only x argument needed!
grad = loggrad(x, obs_lik)   # Fast x-only evaluation</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/observation_likelihood.jl#L7-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.hyperparameters-Tuple{ObservationModel}" href="#GaussianMarkovRandomFields.hyperparameters-Tuple{ObservationModel}"><code>GaussianMarkovRandomFields.hyperparameters</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">hyperparameters(obs_model::ObservationModel) -&gt; Tuple{Vararg{Symbol}}</code></pre><p>Return a tuple of required hyperparameter names for this observation model.</p><p>This method defines which hyperparameters the observation model expects to receive when materializing an ObservationLikelihood instance.</p><p><strong>Arguments</strong></p><ul><li><code>obs_model</code>: An observation model implementing the <code>ObservationModel</code> interface</li></ul><p><strong>Returns</strong></p><ul><li><code>Tuple{Vararg{Symbol}}</code>: Tuple of parameter names (e.g., <code>(:σ,)</code> or <code>(:α, :β)</code>)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">hyperparameters(ExponentialFamily(Normal)) == (:σ,)
hyperparameters(ExponentialFamily(Bernoulli)) == ()</code></pre><p><strong>Implementation</strong></p><p>All observation models should implement this method. The default returns an empty tuple.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/observation_model.jl#L51-L73">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.latent_dimension" href="#GaussianMarkovRandomFields.latent_dimension"><code>GaussianMarkovRandomFields.latent_dimension</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">latent_dimension(obs_model::ObservationModel, y::AbstractVector) -&gt; Union{Int, Nothing}</code></pre><p>Return the latent field dimension for this observation model given observations y.</p><p>For most observation models, this will be <code>length(y)</code> (1:1 mapping). For transformed observation models like <code>LinearlyTransformedObservationModel</code>, this will be the dimension of the design matrix.</p><p>Returns <code>nothing</code> if the latent dimension cannot be determined automatically.</p><p><strong>Arguments</strong></p><ul><li><code>obs_model</code>: An observation model implementing the <code>ObservationModel</code> interface</li><li><code>y</code>: Vector of observations</li></ul><p><strong>Returns</strong></p><ul><li><code>Int</code>: The latent field dimension, or <code>nothing</code> if unknown</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">latent_dimension(ExponentialFamily(Normal), y) == length(y)
latent_dimension(LinearlyTransformedObservationModel(base, A), y) == size(A, 2)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/observation_model.jl#L76-L99">source</a></section><section><div><pre><code class="language-julia hljs">latent_dimension(ef::ExponentialFamily, y::AbstractVector) -&gt; Int</code></pre><p>Return the latent field dimension for exponential family models.</p><p>For ExponentialFamily models, there is a direct 1:1 mapping between observations and latent field components, so the latent dimension equals the observation dimension.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/exponential_family.jl#L204-L211">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.loglik" href="#GaussianMarkovRandomFields.loglik"><code>GaussianMarkovRandomFields.loglik</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">loglik(x, lik::ExponentialFamilyLikelihood) -&gt; Float64</code></pre><p>Generic loglik implementation for all exponential family likelihoods using product_distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/canonical_implementations.jl#L12-L16">source</a></section><section><div><pre><code class="language-julia hljs">loglik(x, lik::NormalLikelihood) -&gt; Float64</code></pre><p>Specialized fast implementation for Normal likelihood that avoids product_distribution overhead.</p><p>Computes: ∑ᵢ logpdf(Normal(μᵢ, σ), yᵢ) = -n/2 * log(2π) - n * log(σ) - 1/(2σ²) * ∑ᵢ(yᵢ - μᵢ)²</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/canonical_implementations.jl#L26-L32">source</a></section><section><div><pre><code class="language-julia hljs">loglik(x, composite_lik::CompositeLikelihood) -&gt; Float64</code></pre><p>Compute the log-likelihood of a composite likelihood by summing component contributions.</p><p>Each component likelihood receives the full latent field <code>x</code> and contributes to the total log-likelihood. This handles cases where components may have overlapping dependencies on the latent field.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/composite/composite_evaluation.jl#L8-L16">source</a></section><section><div><pre><code class="language-julia hljs">loglik(x, obs_lik::AutoDiffLikelihood) -&gt; Real</code></pre><p>Evaluate the log-likelihood function at latent field <code>x</code>.</p><p>Calls the stored log-likelihood function, which typically includes all necessary hyperparameters and data as a closure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/autodiff_likelihood.jl#L224-L231">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.loggrad" href="#GaussianMarkovRandomFields.loggrad"><code>GaussianMarkovRandomFields.loggrad</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">loggrad(x, obs_lik::ObservationLikelihood) -&gt; Vector{Float64}</code></pre><p>Automatic differentiation fallback for ObservationLikelihood gradient computation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/observation_likelihood.jl#L45-L49">source</a></section><section><div><pre><code class="language-julia hljs">loggrad(x, composite_lik::CompositeLikelihood) -&gt; Vector{Float64}</code></pre><p>Compute the gradient of the log-likelihood by summing component gradients.</p><p>Each component contributes its gradient with respect to the full latent field <code>x</code>. For overlapping dependencies, gradients are automatically summed at each latent field element.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/composite/composite_evaluation.jl#L21-L28">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.loghessian" href="#GaussianMarkovRandomFields.loghessian"><code>GaussianMarkovRandomFields.loghessian</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">loghessian(x, obs_lik::ObservationLikelihood) -&gt; AbstractMatrix{Float64}</code></pre><p>Automatic differentiation fallback for ObservationLikelihood Hessian computation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/observation_likelihood.jl#L68-L72">source</a></section><section><div><pre><code class="language-julia hljs">loghessian(x, composite_lik::CompositeLikelihood) -&gt; AbstractMatrix{Float64}</code></pre><p>Compute the Hessian of the log-likelihood by summing component Hessians.</p><p>Each component contributes its Hessian with respect to the full latent field <code>x</code>. For overlapping dependencies, Hessians are automatically summed element-wise.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/composite/composite_evaluation.jl#L41-L48">source</a></section></article><h3 id="Exponential-Family-Models-2"><a class="docs-heading-anchor" href="#Exponential-Family-Models-2">Exponential Family Models</a><a class="docs-heading-anchor-permalink" href="#Exponential-Family-Models-2" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.ExponentialFamily" href="#GaussianMarkovRandomFields.ExponentialFamily"><code>GaussianMarkovRandomFields.ExponentialFamily</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ExponentialFamily{F&lt;:Distribution, L&lt;:LinkFunction} &lt;: ObservationModel</code></pre><p>Observation model for exponential family distributions with link functions.</p><p>This struct represents observation models where the observations come from an exponential  family distribution (Normal, Poisson, Bernoulli, Binomial) and the mean parameter is  related to the latent field through a link function.</p><p><strong>Mathematical Model</strong></p><p>For observations yᵢ and latent field values xᵢ:</p><ul><li>Linear predictor: ηᵢ = xᵢ</li><li>Mean parameter: μᵢ = g⁻¹(ηᵢ) where g is the link function</li><li>Observations: yᵢ ~ F(μᵢ, θ) where F is the distribution family</li></ul><p><strong>Fields</strong></p><ul><li><code>family::Type{F}</code>: The distribution family (e.g., <code>Poisson</code>, <code>Bernoulli</code>)</li><li><code>link::L</code>: The link function connecting mean parameters to linear predictors</li></ul><p><strong>Type Parameters</strong></p><ul><li><code>F</code>: A subtype of <code>Distribution</code> from Distributions.jl</li><li><code>L</code>: A subtype of <code>LinkFunction</code></li></ul><p><strong>Constructors</strong></p><pre><code class="language-julia hljs"># Use canonical link (recommended)
ExponentialFamily(Poisson)        # Uses LogLink()
ExponentialFamily(Bernoulli)      # Uses LogitLink()
ExponentialFamily(Normal)         # Uses IdentityLink()

# Specify custom link function
ExponentialFamily(Poisson, IdentityLink())  # Non-canonical</code></pre><p><strong>Supported Combinations</strong></p><ul><li><code>Normal</code> with <code>IdentityLink</code> (canonical) or <code>LogLink</code></li><li><code>Poisson</code> with <code>LogLink</code> (canonical) or <code>IdentityLink</code>  </li><li><code>Bernoulli</code> with <code>LogitLink</code> (canonical) or <code>LogLink</code></li><li><code>Binomial</code> with <code>LogitLink</code> (canonical) or <code>IdentityLink</code></li></ul><p><strong>Hyperparameters (θ)</strong></p><p>Different families require different hyperparameters:</p><ul><li><code>Normal</code>: <code>θ = [σ]</code> (standard deviation)</li><li><code>Poisson</code>: <code>θ = []</code> (no hyperparameters)</li><li><code>Bernoulli</code>: <code>θ = []</code> (no hyperparameters)</li><li><code>Binomial</code>: <code>θ = [n]</code> (number of trials)</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs"># Poisson model for count data
model = ExponentialFamily(Poisson)
x = [1.0, 2.0]        # Latent field (log scale due to LogLink)
θ = Float64[]         # No hyperparameters  
y = [2, 7]           # Count observations

ll = loglik(x, model, θ, y)
dist = data_distribution(model, x, θ)  # Returns Product distribution

# Bernoulli model for binary data
model = ExponentialFamily(Bernoulli)
x = [0.0, 1.0]       # Latent field (logit scale due to LogitLink)
y = [0, 1]           # Binary observations</code></pre><p><strong>Performance Notes</strong></p><p>Canonical link functions have optimized implementations that avoid redundant computations. Non-canonical links use general chain rule formulations which may be slower.</p><p>See also: <a href="#GaussianMarkovRandomFields.LinkFunction"><code>LinkFunction</code></a>, <a href="#GaussianMarkovRandomFields.loglik"><code>loglik</code></a>, <a href="#GaussianMarkovRandomFields.data_distribution"><code>data_distribution</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/exponential_family.jl#L7-L76">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.data_distribution" href="#GaussianMarkovRandomFields.data_distribution"><code>GaussianMarkovRandomFields.data_distribution</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">data_distribution(obs_model::ExponentialFamily, x, θ_named) -&gt; Distribution</code></pre><p>Construct the data-generating distribution p(y | x, θ).</p><p>This function returns a Distribution object that represents the probability  distribution over observations y given latent field values x and hyperparameters θ. It is used for sampling new observations.</p><p><strong>Arguments</strong></p><ul><li><code>obs_model</code>: An ExponentialFamily observation model</li><li><code>x</code>: Latent field values (vector)  </li><li><code>θ_named</code>: Hyperparameters as a NamedTuple</li></ul><p><strong>Returns</strong></p><p>Distribution object that can be used with <code>rand()</code> to generate observations</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">model = ExponentialFamily(Poisson)
x = [1.0, 2.0]
θ_named = NamedTuple()
dist = data_distribution(model, x, θ_named)
y = rand(dist)  # Sample observations</code></pre><p>Note: For likelihood evaluation L(x|y,θ), use the materialized API:</p><pre><code class="language-julia hljs">obs_lik = obs_model(y; θ_named...)
ll = loglik(x, obs_lik)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/exponential_family.jl#L121-L152">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.ExponentialFamilyLikelihood" href="#GaussianMarkovRandomFields.ExponentialFamilyLikelihood"><code>GaussianMarkovRandomFields.ExponentialFamilyLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ExponentialFamilyLikelihood{L, I} &lt;: ObservationLikelihood</code></pre><p>Abstract type for exponential family observation likelihoods.</p><p>This intermediate type allows for generic implementations that work across all  exponential family distributions while still allowing specialized methods for  specific combinations.</p><p><strong>Type Parameters</strong></p><ul><li><code>L</code>: Link function type</li><li><code>I</code>: Index type (Nothing for non-indexed, UnitRange or Vector for indexed)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/observation_likelihoods.jl#L3-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.NormalLikelihood" href="#GaussianMarkovRandomFields.NormalLikelihood"><code>GaussianMarkovRandomFields.NormalLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NormalLikelihood{L&lt;:LinkFunction} &lt;: ObservationLikelihood</code></pre><p>Materialized Normal observation likelihood with precomputed hyperparameters.</p><p><strong>Fields</strong></p><ul><li><code>link::L</code>: Link function connecting latent field to mean parameter</li><li><code>y::Vector{Float64}</code>: Observed data  </li><li><code>σ::Float64</code>: Standard deviation hyperparameter</li><li><code>inv_σ²::Float64</code>: Precomputed 1/σ² for performance</li><li><code>log_σ::Float64</code>: Precomputed log(σ) for log-likelihood computation</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">obs_model = ExponentialFamily(Normal)
obs_lik = obs_model([1.0, 2.0, 1.5]; σ=0.5)  # NormalLikelihood{IdentityLink}
ll = loglik([0.9, 2.1, 1.4], obs_lik)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/observation_likelihoods.jl#L18-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.PoissonLikelihood" href="#GaussianMarkovRandomFields.PoissonLikelihood"><code>GaussianMarkovRandomFields.PoissonLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">PoissonLikelihood{L&lt;:LinkFunction} &lt;: ObservationLikelihood</code></pre><p>Materialized Poisson observation likelihood.</p><p><strong>Fields</strong></p><ul><li><code>link::L</code>: Link function connecting latent field to rate parameter</li><li><code>y::Vector{Int}</code>: Count observations</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">obs_model = ExponentialFamily(Poisson)  # Uses LogLink by default
obs_lik = obs_model([1, 3, 0, 2])      # PoissonLikelihood{LogLink}
ll = loglik([0.0, 1.1, -2.0, 0.7], obs_lik)  # x values on log scale</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/observation_likelihoods.jl#L46-L61">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.BernoulliLikelihood" href="#GaussianMarkovRandomFields.BernoulliLikelihood"><code>GaussianMarkovRandomFields.BernoulliLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BernoulliLikelihood{L&lt;:LinkFunction} &lt;: ObservationLikelihood</code></pre><p>Materialized Bernoulli observation likelihood for binary data.</p><p><strong>Fields</strong></p><ul><li><code>link::L</code>: Link function connecting latent field to probability parameter  </li><li><code>y::Vector{Int}</code>: Binary observations (0 or 1)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">obs_model = ExponentialFamily(Bernoulli)  # Uses LogitLink by default
obs_lik = obs_model([1, 0, 1, 0])        # BernoulliLikelihood{LogitLink}
ll = loglik([0.5, -0.2, 1.1, -0.8], obs_lik)  # x values on logit scale</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/observation_likelihoods.jl#L68-L83">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.BinomialLikelihood" href="#GaussianMarkovRandomFields.BinomialLikelihood"><code>GaussianMarkovRandomFields.BinomialLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BinomialLikelihood{L&lt;:LinkFunction} &lt;: ObservationLikelihood</code></pre><p>Materialized Binomial observation likelihood.</p><p><strong>Fields</strong></p><ul><li><code>link::L</code>: Link function connecting latent field to probability parameter</li><li><code>y::Vector{Int}</code>: Number of successes for each trial</li><li><code>n::Vector{Int}</code>: Number of trials per observation (can vary across observations)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">obs_model = ExponentialFamily(Binomial)  # Uses LogitLink by default
obs_lik = obs_model([3, 1, 4]; trials=[5, 8, 6])  # BinomialLikelihood{LogitLink}
ll = loglik([0.2, -1.0, 0.8], obs_lik)  # x values on logit scale</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/observation_likelihoods.jl#L90-L106">source</a></section></article><h3 id="Link-Functions"><a class="docs-heading-anchor" href="#Link-Functions">Link Functions</a><a id="Link-Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Link-Functions" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.LinkFunction" href="#GaussianMarkovRandomFields.LinkFunction"><code>GaussianMarkovRandomFields.LinkFunction</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LinkFunction</code></pre><p>Abstract base type for link functions used in exponential family models.</p><p>A link function g(μ) connects the mean parameter μ of a distribution to the linear  predictor η through the relationship g(μ) = η, or equivalently μ = g⁻¹(η).</p><p><strong>Implemented Link Functions</strong></p><ul><li><a href="#GaussianMarkovRandomFields.IdentityLink"><code>IdentityLink</code></a>: g(μ) = μ (for Normal distributions)</li><li><a href="#GaussianMarkovRandomFields.LogLink"><code>LogLink</code></a>: g(μ) = log(μ) (for Poisson distributions)  </li><li><a href="#GaussianMarkovRandomFields.LogitLink"><code>LogitLink</code></a>: g(μ) = logit(μ) (for Bernoulli/Binomial distributions)</li></ul><p><strong>Interface</strong></p><p>Concrete link functions must implement:</p><ul><li><code>apply_link(link, μ)</code>: Apply the link function g(μ)</li><li><code>apply_invlink(link, η)</code>: Apply the inverse link function g⁻¹(η)</li></ul><p>For performance in GMRF computations, they should also implement:</p><ul><li><code>derivative_invlink(link, η)</code>: First derivative of g⁻¹(η)</li><li><code>second_derivative_invlink(link, η)</code>: Second derivative of g⁻¹(η)</li></ul><p>See also: <a href="#GaussianMarkovRandomFields.ExponentialFamily"><code>ExponentialFamily</code></a>, <a href="#GaussianMarkovRandomFields.apply_link"><code>apply_link</code></a>, <a href="#GaussianMarkovRandomFields.apply_invlink"><code>apply_invlink</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/link_functions.jl#L6-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.IdentityLink" href="#GaussianMarkovRandomFields.IdentityLink"><code>GaussianMarkovRandomFields.IdentityLink</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">IdentityLink &lt;: LinkFunction</code></pre><p>Identity link function: g(μ) = μ.</p><p>This is the canonical link for Normal distributions. The mean parameter μ is  directly equal to the linear predictor η.</p><p><strong>Mathematical Definition</strong></p><ul><li>Link: g(μ) = μ</li><li>Inverse link: g⁻¹(η) = η  </li><li>First derivative: d/dη g⁻¹(η) = 1</li><li>Second derivative: d²/dη² g⁻¹(η) = 0</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">link = IdentityLink()
μ = apply_invlink(link, 1.5)  # μ = 1.5
η = apply_link(link, μ)       # η = 1.5</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.LogLink"><code>LogLink</code></a>, <a href="#GaussianMarkovRandomFields.LogitLink"><code>LogitLink</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/link_functions.jl#L32-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.LogLink" href="#GaussianMarkovRandomFields.LogLink"><code>GaussianMarkovRandomFields.LogLink</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LogLink &lt;: LinkFunction</code></pre><p>Logarithmic link function: g(μ) = log(μ).</p><p>This is the canonical link for Poisson and Gamma distributions. It ensures the  mean parameter μ remains positive by mapping the real-valued linear predictor η  to μ = exp(η).</p><p><strong>Mathematical Definition</strong></p><ul><li>Link: g(μ) = log(μ) </li><li>Inverse link: g⁻¹(η) = exp(η)</li><li>First derivative: d/dη g⁻¹(η) = exp(η)</li><li>Second derivative: d²/dη² g⁻¹(η) = exp(η)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">link = LogLink()
μ = apply_invlink(link, 1.0)  # μ = exp(1.0) ≈ 2.718
η = apply_link(link, μ)       # η = log(μ) = 1.0</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.IdentityLink"><code>IdentityLink</code></a>, <a href="#GaussianMarkovRandomFields.LogitLink"><code>LogitLink</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/link_functions.jl#L57-L80">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.LogitLink" href="#GaussianMarkovRandomFields.LogitLink"><code>GaussianMarkovRandomFields.LogitLink</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LogitLink &lt;: LinkFunction</code></pre><p>Logit link function: g(μ) = logit(μ) = log(μ/(1-μ)).</p><p>This is the canonical link for Bernoulli and Binomial distributions. It maps  probabilities μ ∈ (0,1) to the real line via the logistic transformation,  ensuring μ = logistic(η) = 1/(1+exp(-η)) remains a valid probability.</p><p><strong>Mathematical Definition</strong></p><ul><li>Link: g(μ) = logit(μ) = log(μ/(1-μ))</li><li>Inverse link: g⁻¹(η) = logistic(η) = 1/(1+exp(-η))</li><li>First derivative: d/dη g⁻¹(η) = μ(1-μ) where μ = logistic(η)</li><li>Second derivative: d²/dη² g⁻¹(η) = μ(1-μ)(1-2μ)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">link = LogitLink()
μ = apply_invlink(link, 0.0)  # μ = logistic(0.0) = 0.5
η = apply_link(link, μ)       # η = logit(0.5) = 0.0</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.IdentityLink"><code>IdentityLink</code></a>, <a href="#GaussianMarkovRandomFields.LogLink"><code>LogLink</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/link_functions.jl#L83-L106">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.apply_link" href="#GaussianMarkovRandomFields.apply_link"><code>GaussianMarkovRandomFields.apply_link</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">apply_link(link::LinkFunction, μ) -&gt; Real</code></pre><p>Apply the link function g(μ) to transform mean parameters to linear predictor scale.</p><p>This function computes η = g(μ), where g is the link function. This transformation is typically used to ensure the mean parameter satisfies appropriate constraints (e.g., positivity for Poisson, probability bounds for Bernoulli).</p><p><strong>Arguments</strong></p><ul><li><code>link</code>: A link function (IdentityLink, LogLink, or LogitLink)</li><li><code>μ</code>: Mean parameter value(s) in the natural parameter space</li></ul><p><strong>Returns</strong></p><p>The transformed value(s) η on the linear predictor scale</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">apply_link(LogLink(), 2.718)      # ≈ 1.0
apply_link(LogitLink(), 0.5)      # = 0.0  
apply_link(IdentityLink(), 1.5)   # = 1.5</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.apply_invlink"><code>apply_invlink</code></a>, <a href="#GaussianMarkovRandomFields.LinkFunction"><code>LinkFunction</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/link_functions.jl#L109-L133">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.apply_invlink" href="#GaussianMarkovRandomFields.apply_invlink"><code>GaussianMarkovRandomFields.apply_invlink</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">apply_invlink(link::LinkFunction, η) -&gt; Real</code></pre><p>Apply the inverse link function g⁻¹(η) to transform linear predictor to mean parameters.</p><p>This function computes μ = g⁻¹(η), where g⁻¹ is the inverse link function. This is the primary transformation used in GMRF models to convert the latent field values to the natural parameter space of the observation distribution.</p><p><strong>Arguments</strong></p><ul><li><code>link</code>: A link function (IdentityLink, LogLink, or LogitLink)</li><li><code>η</code>: Linear predictor value(s)</li></ul><p><strong>Returns</strong></p><p>The transformed value(s) μ in the natural parameter space</p><p><strong>Examples</strong></p><pre><code class="language-julia hljs">apply_invlink(LogLink(), 1.0)      # ≈ 2.718 (= exp(1))
apply_invlink(LogitLink(), 0.0)    # = 0.5   (= logistic(0))
apply_invlink(IdentityLink(), 1.5) # = 1.5</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.apply_link"><code>apply_link</code></a>, <a href="#GaussianMarkovRandomFields.LinkFunction"><code>LinkFunction</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/exponential_family/link_functions.jl#L138-L162">source</a></section></article><h3 id="Custom-AutoDiff-Models"><a class="docs-heading-anchor" href="#Custom-AutoDiff-Models">Custom AutoDiff Models</a><a id="Custom-AutoDiff-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Custom-AutoDiff-Models" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.AutoDiffObservationModel" href="#GaussianMarkovRandomFields.AutoDiffObservationModel"><code>GaussianMarkovRandomFields.AutoDiffObservationModel</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoDiffObservationModel{F, B, SB, H} &lt;: ObservationModel</code></pre><p>Observation model that uses automatic differentiation for a user-provided log-likelihood function.</p><p>This serves as a factory for creating AutoDiffLikelihood instances. The user provides a  log-likelihood function that can accept hyperparameters, and when materialized, creates a closure with the hyperparameters baked in.</p><p><strong>Type Parameters</strong></p><ul><li><code>F</code>: Type of the log-likelihood function  </li><li><code>B</code>: Type of the AD backend for gradients</li><li><code>SB</code>: Type of the AD backend for Hessians</li><li><code>H</code>: Type of the hyperparameters tuple</li></ul><p><strong>Fields</strong></p><ul><li><code>loglik_func::F</code>: User-provided log-likelihood function with signature <code>(x; kwargs...) -&gt; Real</code></li><li><code>n_latent::Int</code>: Number of latent field components</li><li><code>grad_backend::B</code>: AD backend for gradient computation</li><li><code>hess_backend::SB</code>: AD backend for Hessian computation</li><li><code>hyperparams::H</code>: Tuple of hyperparameter names that this model expects</li></ul><p><strong>Usage</strong></p><pre><code class="language-julia hljs"># Define your log-likelihood function with hyperparameters
function my_loglik(x; σ=1.0, y=[1.0, 2.0])
    μ = x  # or some transformation of x
    return -0.5 * sum((y .- μ).^2) / σ^2 - length(y) * log(σ)
end

# Create observation model specifying expected hyperparameters
obs_model = AutoDiffObservationModel(my_loglik; n_latent=2, hyperparams=(:σ, :y))

# Materialize with specific hyperparameters
obs_lik = obs_model(σ=0.5, y=[1.2, 1.8])  # Creates AutoDiffLikelihood

# Use normally
ll = loglik(x, obs_lik)
grad = loggrad(x, obs_lik)
hess = loghessian(x, obs_lik)</code></pre><p>See also: <a href="#GaussianMarkovRandomFields.AutoDiffLikelihood"><code>AutoDiffLikelihood</code></a>, <a href="#GaussianMarkovRandomFields.ObservationModel"><code>ObservationModel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/autodiff_likelihood.jl#L66-L109">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.AutoDiffLikelihood" href="#GaussianMarkovRandomFields.AutoDiffLikelihood"><code>GaussianMarkovRandomFields.AutoDiffLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">AutoDiffLikelihood{F, B, SB, GP, HP} &lt;: ObservationLikelihood</code></pre><p>Automatic differentiation-based observation likelihood that wraps a user-provided log-likelihood function.</p><p>This is a materialized likelihood created from an AutoDiffObservationModel. The log-likelihood function is typically a closure that already includes hyperparameters and data.</p><p><strong>Type Parameters</strong></p><ul><li><code>F</code>: Type of the log-likelihood function (usually a closure)</li><li><code>B</code>: Type of the AD backend for gradients</li><li><code>SB</code>: Type of the AD backend for Hessians</li><li><code>GP</code>: Type of the gradient preparation object</li><li><code>HP</code>: Type of the Hessian preparation object</li></ul><p><strong>Fields</strong></p><ul><li><code>loglik_func::F</code>: Log-likelihood function with signature <code>(x) -&gt; Real</code></li><li><code>grad_backend::B</code>: AD backend for gradient computation</li><li><code>hess_backend::SB</code>: AD backend for Hessian computation</li><li><code>grad_prep::GP</code>: Preparation object for gradient computation</li><li><code>hess_prep::HP</code>: Preparation object for Hessian computation</li></ul><p><strong>Usage</strong></p><p>Typically created via AutoDiffObservationModel factory:</p><pre><code class="language-julia hljs"># Define your log-likelihood function with hyperparameters
function my_loglik(x; σ=1.0, y=[1.0, 2.0])
    μ = x  # or some transformation of x
    return -0.5 * sum((y .- μ).^2) / σ^2 - length(y) * log(σ)
end

# Create observation model
obs_model = AutoDiffObservationModel(my_loglik, n_latent=2)

# Materialize with data and hyperparameters
obs_lik = obs_model(σ=0.5, y=[1.2, 1.8])  # Creates AutoDiffLikelihood

# Use in the standard way
x = [1.1, 1.9]
ll = loglik(x, obs_lik)
grad = loggrad(x, obs_lik)  # Uses prepared AD with optimal backends
hess = loghessian(x, obs_lik)  # Automatically sparse when available!</code></pre><p><strong>Sparse Hessian Features</strong></p><p>The Hessian computation automatically:</p><ul><li>Detects sparsity pattern using TracerSparsityDetector</li><li>Uses greedy coloring for efficient computation</li><li>Returns a sparse matrix when beneficial</li><li>Falls back to dense computation for small problems</li></ul><p>See also: <a href="#GaussianMarkovRandomFields.loglik"><code>loglik</code></a>, <a href="#GaussianMarkovRandomFields.loggrad"><code>loggrad</code></a>, <a href="#GaussianMarkovRandomFields.loghessian"><code>loghessian</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/autodiff_likelihood.jl#L5-L57">source</a></section></article><h3 id="Advanced-Features-2"><a class="docs-heading-anchor" href="#Advanced-Features-2">Advanced Features</a><a class="docs-heading-anchor-permalink" href="#Advanced-Features-2" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.LinearlyTransformedObservationModel" href="#GaussianMarkovRandomFields.LinearlyTransformedObservationModel"><code>GaussianMarkovRandomFields.LinearlyTransformedObservationModel</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LinearlyTransformedObservationModel{M, A} &lt;: ObservationModel</code></pre><p>Observation model that applies a linear transformation to the latent field before  passing to a base observation model. This enables GLM-style modeling with design  matrices while maintaining full compatibility with existing observation models.</p><p><strong>Mathematical Foundation</strong></p><p>The wrapper transforms the full latent field x_full to linear predictors η via a  design matrix A:</p><ul><li>η = A * x_full  </li><li>Base model operates on η as usual: p(y | η, θ)</li><li>Chain rule applied for gradients/Hessians: <ul><li>∇<em>{x</em>full} ℓ = A^T ∇_η ℓ</li><li>∇²<em>{x</em>full} ℓ = A^T ∇²_η ℓ A</li></ul></li></ul><p><strong>Type Parameters</strong></p><ul><li><code>M &lt;: ObservationModel</code>: Type of the base observation model</li><li><code>A</code>: Type of the design matrix (typically AbstractMatrix)</li></ul><p><strong>Fields</strong></p><ul><li><code>base_model::M</code>: The underlying observation model that operates on linear predictors</li><li><code>design_matrix::A</code>: Matrix mapping full latent field to observation-specific linear predictors</li></ul><p><strong>Usage Pattern</strong></p><pre><code class="language-julia hljs"># Step 1: Create base observation model
base_model = ExponentialFamily(Poisson)  # LogLink by default

# Step 2: Create design matrix (maps latent field to linear predictors)
# For: y ~ intercept + temperature + group_effects
A = [1.0  20.0  1.0  0.0  0.0;   # obs 1: intercept + temp + group1
     1.0  25.0  1.0  0.0  0.0;   # obs 2: intercept + temp + group1  
     1.0  30.0  0.0  1.0  0.0;   # obs 3: intercept + temp + group2
     1.0  15.0  0.0  0.0  1.0]   # obs 4: intercept + temp + group3

# Step 3: Create wrapped model
obs_model = LinearlyTransformedObservationModel(base_model, A)

# Step 4: Use in GMRF model - latent field now includes all components
# x_full = [β₀, β₁, u₁, u₂, u₃]  # intercept, slope, group effects

# Step 5: Materialize with data and hyperparameters
obs_lik = obs_model(y; σ=1.2)  # Creates LinearlyTransformedLikelihood

# Step 6: Fast evaluation in optimization loops
ll = loglik(x_full, obs_lik)</code></pre><p><strong>Hyperparameters</strong></p><p>All hyperparameters come from the base observation model. The design matrix  introduces no new hyperparameters - it&#39;s a fixed linear transformation.</p><p>See also: <a href="#GaussianMarkovRandomFields.LinearlyTransformedLikelihood"><code>LinearlyTransformedLikelihood</code></a>, <a href="#GaussianMarkovRandomFields.ExponentialFamily"><code>ExponentialFamily</code></a>, <a href="#GaussianMarkovRandomFields.ObservationModel"><code>ObservationModel</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/linearly_transformed.jl#L6-L60">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.LinearlyTransformedLikelihood" href="#GaussianMarkovRandomFields.LinearlyTransformedLikelihood"><code>GaussianMarkovRandomFields.LinearlyTransformedLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">LinearlyTransformedLikelihood{L, A} &lt;: ObservationLikelihood</code></pre><p>Materialized likelihood for LinearlyTransformedObservationModel with precomputed  base likelihood and design matrix.</p><p>This is created by calling a LinearlyTransformedObservationModel instance with  data and hyperparameters, following the factory pattern used throughout the package.</p><p><strong>Type Parameters</strong></p><ul><li><code>L &lt;: ObservationLikelihood</code>: Type of the materialized base likelihood</li><li><code>A</code>: Type of the design matrix</li></ul><p><strong>Fields</strong></p><ul><li><code>base_likelihood::L</code>: Materialized base observation likelihood (contains y and θ)</li><li><code>design_matrix::A</code>: Design matrix mapping full latent field to linear predictors</li></ul><p><strong>Usage</strong></p><p>This type is typically created automatically:</p><pre><code class="language-julia hljs">ltom = LinearlyTransformedObservationModel(base_model, design_matrix)
ltlik = ltom(y; σ=1.2)  # Creates LinearlyTransformedLikelihood
ll = loglik(x_full, ltlik)  # Fast evaluation</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/linearly_transformed.jl#L81-L105">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.BinomialObservations" href="#GaussianMarkovRandomFields.BinomialObservations"><code>GaussianMarkovRandomFields.BinomialObservations</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">BinomialObservations &lt;: AbstractVector{Tuple{Int, Int}}</code></pre><p>Combined observation type for binomial data containing both successes and trials.</p><p>This type packages binomial observation data (number of successes and trials) into a single vector-like object where each element is a (successes, trials) tuple.</p><p><strong>Fields</strong></p><ul><li><code>successes::Vector{Int}</code>: Number of successes for each observation</li><li><code>trials::Vector{Int}</code>: Number of trials for each observation</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs"># Create binomial observations
y = BinomialObservations([3, 1, 4], [5, 8, 6])

# Access as tuples
y[1]  # (3, 5)
y[2]  # (1, 8)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/binomial_observations.jl#L3-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.successes" href="#GaussianMarkovRandomFields.successes"><code>GaussianMarkovRandomFields.successes</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">successes(y::BinomialObservations) -&gt; Vector{Int}</code></pre><p>Extract the successes vector from binomial observations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/binomial_observations.jl#L61-L65">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.trials" href="#GaussianMarkovRandomFields.trials"><code>GaussianMarkovRandomFields.trials</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">trials(y::BinomialObservations) -&gt; Vector{Int}</code></pre><p>Extract the trials vector from binomial observations.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/binomial_observations.jl#L68-L72">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.CompositeObservations" href="#GaussianMarkovRandomFields.CompositeObservations"><code>GaussianMarkovRandomFields.CompositeObservations</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CompositeObservations{T&lt;:Tuple} &lt;: AbstractVector{Float64}</code></pre><p>A composite observation vector that stores observation data as a tuple of component vectors.</p><p>This type implements the <code>AbstractVector</code> interface and allows combining different observation datasets while maintaining their structure. The composite vector presents a unified view where indexing delegates to the appropriate component vector.</p><p><strong>Fields</strong></p><ul><li><code>components::T</code>: Tuple of observation vectors, one per likelihood component</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">y1 = [1.0, 2.0, 3.0]  # Gaussian observations
y2 = [4.0, 5.0]       # More Gaussian observations
y_composite = CompositeObservations((y1, y2))

length(y_composite)    # 5
y_composite[1]         # 1.0
y_composite[4]         # 4.0
collect(y_composite)   # [1.0, 2.0, 3.0, 4.0, 5.0]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/composite/composite_observations.jl#L1-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.CompositeObservationModel" href="#GaussianMarkovRandomFields.CompositeObservationModel"><code>GaussianMarkovRandomFields.CompositeObservationModel</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CompositeObservationModel{T&lt;:Tuple} &lt;: ObservationModel</code></pre><p>An observation model that combines multiple component observation models.</p><p>This type follows the factory pattern - it stores component observation models and  creates <code>CompositeLikelihood</code> instances when called with observation data and hyperparameters.</p><p><strong>Fields</strong></p><ul><li><code>components::T</code>: Tuple of component observation models for type stability</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">gaussian_model = ExponentialFamily(Normal)
poisson_model = ExponentialFamily(Poisson)
composite_model = CompositeObservationModel((gaussian_model, poisson_model))

# Materialize with data and hyperparameters
y_composite = CompositeObservations(([1.0, 2.0], [3, 4]))
composite_lik = composite_model(y_composite; σ=1.5)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/composite/composite_observation_model.jl#L1-L22">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="GaussianMarkovRandomFields.CompositeLikelihood" href="#GaussianMarkovRandomFields.CompositeLikelihood"><code>GaussianMarkovRandomFields.CompositeLikelihood</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CompositeLikelihood{T&lt;:Tuple} &lt;: ObservationLikelihood</code></pre><p>A materialized composite likelihood that combines multiple component likelihoods.</p><p>Created by calling a <code>CompositeObservationModel</code> with observation data and hyperparameters. Provides efficient evaluation of log-likelihood, gradient, and Hessian by summing contributions from all component likelihoods.</p><p><strong>Fields</strong></p><ul><li><code>components::T</code>: Tuple of materialized component likelihoods</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/39d819cd96fe04b1cbf04570c7357444eb6879c9/src/observation_models/composite/composite_observation_model.jl#L34-L45">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../latent_models/">« Latent Models</a><a class="docs-footer-nextpage" href="../gaussian_approximation/">Gaussian Approximation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Wednesday 27 August 2025 18:28">Wednesday 27 August 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
