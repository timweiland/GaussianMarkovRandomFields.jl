<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>KL-minimizing Sparse GP Approximations | GMRFs.jl</title>
    <meta name="description" content="Documentation for GaussianMarkovRandomFields.jl">
    <meta name="generator" content="VitePress v1.6.4">
    <link rel="preload stylesheet" href="/GaussianMarkovRandomFields.jl/stable/assets/style.CYBIgdap.css" as="style">
    <link rel="preload stylesheet" href="/GaussianMarkovRandomFields.jl/stable/vp-icons.css" as="style">
    
    <script type="module" src="/GaussianMarkovRandomFields.jl/stable/assets/app.DSz2lMri.js"></script>
    <link rel="preload" href="/GaussianMarkovRandomFields.jl/stable/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/GaussianMarkovRandomFields.jl/stable/assets/chunks/theme.Bh-nmtdo.js">
    <link rel="modulepreload" href="/GaussianMarkovRandomFields.jl/stable/assets/chunks/framework.CskZLg5I.js">
    <link rel="modulepreload" href="/GaussianMarkovRandomFields.jl/stable/assets/reference_kl_approximation.md.BC4PnrO1.lean.js">
    <script src="/GaussianMarkovRandomFields.jl/versions.js"></script>
    <script src="/GaussianMarkovRandomFields.jl/stable/siteinfo.js"></script>
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-a9a9e638><!--[--><!--]--><!--[--><span tabindex="-1" data-v-492508fc></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-492508fc>Skip to content</a><!--]--><!----><header class="VPNav" data-v-a9a9e638 data-v-f1e365da><div class="VPNavBar" data-v-f1e365da data-v-822684d1><div class="wrapper" data-v-822684d1><div class="container" data-v-822684d1><div class="title" data-v-822684d1><div class="VPNavBarTitle has-sidebar" data-v-822684d1 data-v-0f4f798b><a class="title" href="/GaussianMarkovRandomFields.jl/stable/" data-v-0f4f798b><!--[--><!--]--><!--[--><img class="VPImage logo" src="/GaussianMarkovRandomFields.jl/stable/logo.svg" width="24" height="24" alt data-v-35a7d0b8><!--]--><span data-v-0f4f798b>GMRFs.jl</span><!--[--><!--]--></a></div></div><div class="content" data-v-822684d1><div class="content-body" data-v-822684d1><!--[--><!--]--><div class="VPNavBarSearch search" data-v-822684d1><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-822684d1 data-v-e6d46098><span id="main-nav-aria-label" class="visually-hidden" data-v-e6d46098> Main Navigation </span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/GaussianMarkovRandomFields.jl/stable/index" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Home</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Tutorials</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/index" data-v-acbfed09><!--[--><span data-v-acbfed09>Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/autoregressive_models" data-v-acbfed09><!--[--><span data-v-acbfed09>Building autoregressive models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/spatial_modelling_spdes" data-v-acbfed09><!--[--><span data-v-acbfed09>Spatial Modelling with SPDEs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/spatiotemporal_modelling" data-v-acbfed09><!--[--><span data-v-acbfed09>Spatiotemporal Modelling with SPDEs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/boundary_conditions" data-v-acbfed09><!--[--><span data-v-acbfed09>Boundary Conditions for SPDEs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/bernoulli_spatial_classification" data-v-acbfed09><!--[--><span data-v-acbfed09>Bernoulli Spatial Classification with a Matérn Field</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/bym_scotland_lip_cancer" data-v-acbfed09><!--[--><span data-v-acbfed09>Advanced GMRF modelling for disease mapping</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/kl_approximation" data-v-acbfed09><!--[--><span data-v-acbfed09>KL-minimizing Sparse GMRF Approximations to Gaussian Processes</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/automatic_differentiation" data-v-acbfed09><!--[--><span data-v-acbfed09>Automatic Differentiation for GMRF Hyperparameters</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup active" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>API Reference</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/index" data-v-acbfed09><!--[--><span data-v-acbfed09>Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/gmrfs" data-v-acbfed09><!--[--><span data-v-acbfed09>GMRFs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/latent_models" data-v-acbfed09><!--[--><span data-v-acbfed09>Latent Models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/observation_models" data-v-acbfed09><!--[--><span data-v-acbfed09>Observation Models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/gaussian_approximation" data-v-acbfed09><!--[--><span data-v-acbfed09>Gaussian Approximation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/hard_constraints" data-v-acbfed09><!--[--><span data-v-acbfed09>Hard Constraints</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/autodiff" data-v-acbfed09><!--[--><span data-v-acbfed09>Automatic Differentiation</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link active" href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation" data-v-acbfed09><!--[--><span data-v-acbfed09>KL Approximations</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/spdes" data-v-acbfed09><!--[--><span data-v-acbfed09>SPDEs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/discretizations" data-v-acbfed09><!--[--><span data-v-acbfed09>Discretizations</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/meshes" data-v-acbfed09><!--[--><span data-v-acbfed09>Meshes</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/plotting" data-v-acbfed09><!--[--><span data-v-acbfed09>Plotting</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/solvers" data-v-acbfed09><!--[--><span data-v-acbfed09>Solvers</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/autoregressive" data-v-acbfed09><!--[--><span data-v-acbfed09>Autoregressive Models</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/linear_maps" data-v-acbfed09><!--[--><span data-v-acbfed09>Linear maps</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/reference/preconditioners" data-v-acbfed09><!--[--><span data-v-acbfed09>Preconditioners</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/GaussianMarkovRandomFields.jl/stable/bibliography" tabindex="0" data-v-e6d46098 data-v-956ec74c><!--[--><span data-v-956ec74c>Bibliography</span><!--]--></a><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-e6d46098 data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><!----><span data-v-04f5c5e9>Developer Documentation</span><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><div class="items" data-v-7dd3104a><!--[--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/index" data-v-acbfed09><!--[--><span data-v-acbfed09>Overview</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/solvers" data-v-acbfed09><!--[--><span data-v-acbfed09>Solvers</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/spdes" data-v-acbfed09><!--[--><span data-v-acbfed09>SPDEs</span><!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-7dd3104a data-v-acbfed09><a class="VPLink link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/discretizations" data-v-acbfed09><!--[--><span data-v-acbfed09>Discretizations</span><!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><!----><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-822684d1 data-v-af096f4a><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-af096f4a data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-822684d1 data-v-164c457f data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-822684d1 data-v-925effce data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-04f5c5e9><span class="vpi-more-horizontal icon" data-v-04f5c5e9></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--[--><!----><div class="group" data-v-925effce><div class="item appearance" data-v-925effce><p class="label" data-v-925effce>Appearance</p><div class="appearance-action" data-v-925effce><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-925effce data-v-e40a8bb6 data-v-4a1c76db><span class="check" data-v-4a1c76db><span class="icon" data-v-4a1c76db><!--[--><span class="vpi-sun sun" data-v-e40a8bb6></span><span class="vpi-moon moon" data-v-e40a8bb6></span><!--]--></span></span></button></div></div></div><div class="group" data-v-925effce><div class="item social-links" data-v-925effce><div class="VPSocialLinks social-links-list" data-v-925effce data-v-ee7a9424><!--[--><a class="VPSocialLink no-icon" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl" aria-label="github" target="_blank" rel="noopener" data-v-ee7a9424 data-v-d26d30cb><span class="vpi-social-github"></span></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--[--><!--[--><div class="VPFlyout VPNolebaseEnhancedReadabilitiesMenu VPNolebaseEnhancedReadabilitiesMenuFlyout" aria-label="Enhanced Readability" role="menuitem" data-v-04f5c5e9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-04f5c5e9><span class="text" data-v-04f5c5e9><span class="i-icon-park-outline:book-open option-icon" data-v-04f5c5e9></span><!----><span class="vpi-chevron-down text-icon" data-v-04f5c5e9></span></span></button><div class="menu" data-v-04f5c5e9><div class="VPMenu" data-v-04f5c5e9 data-v-7dd3104a><!----><!--[--><!--]--></div></div></div><!--]--><!--]--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-822684d1 data-v-5dea55bf><span class="container" data-v-5dea55bf><span class="top" data-v-5dea55bf></span><span class="middle" data-v-5dea55bf></span><span class="bottom" data-v-5dea55bf></span></span></button></div></div></div></div><div class="divider" data-v-822684d1><div class="divider-line" data-v-822684d1></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-a9a9e638 data-v-070ab83d><div class="container" data-v-070ab83d><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-070ab83d><span class="vpi-align-left menu-icon" data-v-070ab83d></span><span class="menu-text" data-v-070ab83d>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-070ab83d data-v-168ddf5d><button data-v-168ddf5d>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-a9a9e638 data-v-18756405><div class="curtain" data-v-18756405></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-18756405><span class="visually-hidden" id="sidebar-aria-label" data-v-18756405> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0" data-v-9e426adc data-v-a4b0d9bf><!----><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/index" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Home</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>Tutorials</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/index" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/autoregressive_models" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Building autoregressive models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/spatial_modelling_spdes" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Spatial Modelling with SPDEs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/spatiotemporal_modelling" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Spatiotemporal Modelling with SPDEs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/boundary_conditions" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Boundary Conditions for SPDEs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/bernoulli_spatial_classification" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Bernoulli Spatial Classification with a Matérn Field</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/bym_scotland_lip_cancer" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Advanced GMRF modelling for disease mapping</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/kl_approximation" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>KL-minimizing Sparse GMRF Approximations to Gaussian Processes</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/tutorials/automatic_differentiation" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Automatic Differentiation for GMRF Hyperparameters</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible has-active" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>API Reference</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/index" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/gmrfs" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>GMRFs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/latent_models" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Latent Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/observation_models" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Observation Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/gaussian_approximation" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Gaussian Approximation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/hard_constraints" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Hard Constraints</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/autodiff" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Automatic Differentiation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>KL Approximations</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/spdes" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>SPDEs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/discretizations" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Discretizations</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/meshes" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Meshes</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/plotting" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Plotting</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/solvers" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Solvers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/autoregressive" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Autoregressive Models</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/linear_maps" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Linear maps</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/reference/preconditioners" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Preconditioners</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0" data-v-9e426adc data-v-a4b0d9bf><!----><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/bibliography" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Bibliography</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><div class="no-transition group" data-v-9e426adc><section class="VPSidebarItem level-0 collapsible" data-v-9e426adc data-v-a4b0d9bf><div class="item" role="button" tabindex="0" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><h2 class="text" data-v-a4b0d9bf>Developer Documentation</h2><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-a4b0d9bf><span class="vpi-chevron-right caret-icon" data-v-a4b0d9bf></span></div></div><div class="items" data-v-a4b0d9bf><!--[--><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/index" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Overview</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/solvers" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Solvers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/spdes" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>SPDEs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-1 is-link" data-v-a4b0d9bf data-v-a4b0d9bf><div class="item" data-v-a4b0d9bf><div class="indicator" data-v-a4b0d9bf></div><a class="VPLink link link" href="/GaussianMarkovRandomFields.jl/stable/dev-docs/discretizations" data-v-a4b0d9bf><!--[--><p class="text" data-v-a4b0d9bf>Discretizations</p><!--]--></a><!----></div><!----></div><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-a9a9e638 data-v-91765379><div class="VPDoc has-sidebar has-aside" data-v-91765379 data-v-83890dd9><!--[--><!--]--><div class="container" data-v-83890dd9><div class="aside" data-v-83890dd9><div class="aside-curtain" data-v-83890dd9></div><div class="aside-container" data-v-83890dd9><div class="aside-content" data-v-83890dd9><div class="VPDocAside" data-v-83890dd9 data-v-6d7b3c46><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-6d7b3c46 data-v-b38bf2ff><div class="content" data-v-b38bf2ff><div class="outline-marker" data-v-b38bf2ff></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-b38bf2ff>On this page</div><ul class="VPDocOutlineItem root" data-v-b38bf2ff data-v-3f927ebe><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-6d7b3c46></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-83890dd9><div class="content-container" data-v-83890dd9><!--[--><!--]--><main class="main" data-v-83890dd9><div style="position:relative;" class="vp-doc _GaussianMarkovRandomFields_jl_stable_reference_kl_approximation" data-v-83890dd9><div><h1 id="KL-minimizing-Sparse-GP-Approximations" tabindex="-1">KL-minimizing Sparse GP Approximations <a class="header-anchor" href="#KL-minimizing-Sparse-GP-Approximations" aria-label="Permalink to &quot;KL-minimizing Sparse GP Approximations {#KL-minimizing-Sparse-GP-Approximations}&quot;">​</a></h1><p>Sparse GMRF approximations to Gaussian processes defined by kernel (covariance) matrices using KL-divergence minimizing sparse Cholesky factorization.</p><p>These functions enable efficient large-scale GP inference by approximating a dense kernel matrix with a sparse precision matrix using spatially-informed Cholesky factorization that minimizes the Kullback-Leibler divergence.</p><h2 id="Overview" tabindex="-1">Overview <a class="header-anchor" href="#Overview" aria-label="Permalink to &quot;Overview {#Overview}&quot;">​</a></h2><p>The KL-divergence minimizing sparse Cholesky approximation constructs a sparse GMRF from a kernel matrix through a four-stage algorithm that exploits spatial structure to determine which precision matrix entries can be safely set to zero.</p><h3 id="1.-Reverse-Maximin-Ordering" tabindex="-1">1. Reverse Maximin Ordering <a class="header-anchor" href="#1.-Reverse-Maximin-Ordering" aria-label="Permalink to &quot;1. Reverse Maximin Ordering {#1.-Reverse-Maximin-Ordering}&quot;">​</a></h3><p>The algorithm begins by computing a reverse maximin ordering of the input points. This ordering selects points greedily to maximize the distance to previously selected points, creating a natural hierarchical structure where similar points tend to appear consecutively. The result is a permutation vector <code>P</code> that reorders the points for optimal sparsity.</p><h3 id="2.-Sparsity-Pattern-Construction" tabindex="-1">2. Sparsity Pattern Construction <a class="header-anchor" href="#2.-Sparsity-Pattern-Construction" aria-label="Permalink to &quot;2. Sparsity Pattern Construction {#2.-Sparsity-Pattern-Construction}&quot;">​</a></h3><p>Based on the ordering and spatial locations, the algorithm determines a sparsity pattern using a neighborhood radius <code>ρ × ℓᵢ</code>, where <code>ℓᵢ</code> is the maximin distance for point <code>i</code>. This radius defines which matrix entries will be nonzero. Larger <code>ρ</code> values create denser (and more accurate) approximations at the cost of increased computational expense.</p><h3 id="3.-Supernodal-Clustering-Optional,-Default" tabindex="-1">3. Supernodal Clustering (Optional, Default) <a class="header-anchor" href="#3.-Supernodal-Clustering-Optional,-Default" aria-label="Permalink to &quot;3. Supernodal Clustering (Optional, Default) {#3.-Supernodal-Clustering-Optional,-Default}&quot;">​</a></h3><p>By default, the algorithm uses supernodal clustering to group columns with similar sparsity patterns into &quot;supernodes&quot;. Rather than solving many small linear systems (one per column), the algorithm solves fewer but larger systems (one per supernode). This tends to be much more efficient since larger matrix operations can take advantage of optimized BLAS routines.</p><p>The clustering parameter <code>λ</code> (typically 1.5) controls the similarity threshold: columns are grouped together if their maximin distances differ by less than this factor.</p><h3 id="4.-Cholesky-Factorization" tabindex="-1">4. Cholesky Factorization <a class="header-anchor" href="#4.-Cholesky-Factorization" aria-label="Permalink to &quot;4. Cholesky Factorization {#4.-Cholesky-Factorization}&quot;">​</a></h3><p>The algorithm fills in the sparse Cholesky factor <code>L</code> such that <code>L * L&#39; ≈ (PKP&#39;)⁻¹</code>, where <code>K</code> is the covariance matrix. For each supernode (or individual column when not using supernodes), the algorithm extracts the relevant submatrix of the covariance, solves a small dense Cholesky problem, and fills in the corresponding entries of <code>L</code>. The result is a GMRF with sparse precision matrix <code>Q ≈ K⁻¹</code> that enables efficient inference.</p><h2 id="Algorithm-Parameters" tabindex="-1">Algorithm Parameters <a class="header-anchor" href="#Algorithm-Parameters" aria-label="Permalink to &quot;Algorithm Parameters {#Algorithm-Parameters}&quot;">​</a></h2><p>The algorithm has two main tuning parameters:</p><p>The sparsity radius parameter <code>ρ</code> (default: 2.0) controls the neighborhood size for determining sparsity. Larger values create denser approximations with better accuracy but higher computational cost. Typical values range from 1.5 to 3.0, with 2.0-2.5 being a good balanced choice for most applications.</p><p>The supernodal clustering threshold <code>λ</code> (default: 1.5) controls how columns are grouped into supernodes. Setting it to <code>nothing</code> disables supernodal clustering entirely, which can be useful for very small problems or debugging. Higher values create larger supernodes, which can improve performance if the problem structure is favorable.</p><h2 id="Main-Functions" tabindex="-1">Main Functions <a class="header-anchor" href="#Main-Functions" aria-label="Permalink to &quot;Main Functions {#Main-Functions}&quot;">​</a></h2><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.approximate_gmrf_kl" href="#GaussianMarkovRandomFields.approximate_gmrf_kl"><span class="jlbinding">GaussianMarkovRandomFields.approximate_gmrf_kl</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">approximate_gmrf_kl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(kernel_mat</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; ρ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, λ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, alg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LinearSolve</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">CHOLMODFactorization</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">())</span></span></code></pre></div><p>Construct a sparse GMRF approximation from a kernel (covariance) matrix.</p><p>Given a kernel matrix <code>K</code> (covariance matrix) obtained by evaluating a kernel function at input points <code>X</code>, construct a sparse Gaussian Markov Random Field (GMRF) that approximates the corresponding Gaussian process.</p><p><strong>Arguments</strong></p><ul><li><p><code>kernel_mat::AbstractMatrix</code>: Kernel (covariance) matrix</p></li><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension, n is number of points)</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>ρ::Real = 2.0</code>: Sparsity pattern radius parameter. Larger values create denser, more accurate approximations. Typical range: [1.5, 3.0].</p></li><li><p><code>λ::Union{Real,Nothing} = 1.5</code>: Supernodal clustering parameter. If <code>nothing</code>, uses standard column-by-column factorization. If a number, uses supernodal clustering (typically 1.5). Supernodal factorization is usually faster due to improved cache efficiency.</p></li><li><p><code>alg = LinearSolve.CHOLMODFactorization()</code>: LinearSolve algorithm for the resulting GMRF</p></li></ul><p><strong>Returns</strong></p><ul><li><code>::GMRF</code>: A sparse GMRF with zero mean and sparse precision matrix approximating <code>K⁻¹</code></li></ul><p><strong>Examples</strong></p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KernelFunctions, GaussianMarkovRandomFields</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create spatial grid</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> hcat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([[x, y] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Define kernel and compute kernel matrix</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kernel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> with_lengthscale</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Matern32Kernel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">K </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> kernelmatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(kernel, X, obsdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create sparse GMRF approximation (uses supernodal by default)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gmrf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> approximate_gmrf_kl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(K, X; ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Use non-supernodal version</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gmrf_nonsupernodal </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> approximate_gmrf_kl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(K, X; ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, λ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">nothing</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Use for inference</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">posterior </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> linear_condition</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(gmrf; A</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">A, Q_ϵ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Q_ϵ, y</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y)</span></span></code></pre></div><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/gmrfs#GaussianMarkovRandomFields.GMRF"><code>GMRF</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/gmrfs#GaussianMarkovRandomFields.linear_condition"><code>linear_condition</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/kl_cholesky.jl#L156-L202" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.sparse_approximate_cholesky" href="#GaussianMarkovRandomFields.sparse_approximate_cholesky"><span class="jlbinding">GaussianMarkovRandomFields.sparse_approximate_cholesky</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sparse_approximate_cholesky</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Θ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; ρ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, λ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Compute sparse approximate Cholesky factorization with automatic sparsity pattern.</p><p>Given a covariance matrix <code>Θ</code> and spatial input points <code>X</code>, compute a sparse approximate Cholesky factor <code>L</code> and permutation <code>P</code> such that <code>L * L&#39; ≈ (Θ[P, P])⁻¹</code>.</p><p><strong>Arguments</strong></p><ul><li><p><code>Θ::AbstractMatrix</code>: Covariance matrix to be inverted approximately</p></li><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension, n is number of points)</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>ρ::Real = 2.0</code>: Sparsity pattern radius parameter. Controls the neighborhood size used to determine sparsity. Larger values create denser (more accurate) approximations. Typical values are in the range [1.5, 3.0].</p></li><li><p><code>λ::Union{Real,Nothing} = 1.5</code>: Supernodal clustering parameter. If <code>nothing</code>, uses standard column-by-column factorization. If a number, uses supernodal clustering with the given threshold (typically 1.5). Supernodal factorization groups nearby columns together for improved cache efficiency and is usually faster.</p></li></ul><p><strong>Returns</strong></p><ul><li><p><code>L::SparseMatrixCSC</code>: Lower-triangular sparse Cholesky factor in permuted coordinates</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector from the reverse maximin ordering</p></li></ul><p><strong>Details</strong></p><p>The permutation <code>P</code> reorders the points to achieve better sparsity. The returned factor <code>L</code> satisfies <code>L * L&#39; ≈ (Θ[P, P])⁻¹</code>, or equivalently <code>(L * L&#39;)[invperm(P), invperm(P)] ≈ Θ⁻¹</code>.</p><p>When <code>λ !== nothing</code>, the algorithm uses supernodal clustering to group columns with similar sparsity patterns, solving larger dense systems less frequently rather than many small systems. This typically improves performance through better cache locality.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky!"><code>sparse_approximate_cholesky!</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.approximate_gmrf_kl"><code>approximate_gmrf_kl</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering"><code>reverse_maximin_ordering</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/kl_cholesky.jl#L104-L139" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.sparse_approximate_cholesky!" href="#GaussianMarkovRandomFields.sparse_approximate_cholesky!"><span class="jlbinding">GaussianMarkovRandomFields.sparse_approximate_cholesky!</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sparse_approximate_cholesky!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Θ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, L</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SparseMatrixCSC</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>In-place computation of sparse approximate Cholesky factorization.</p><p>Fill the nonzero values of the lower-triangular sparse matrix <code>L</code> such that <code>L * L&#39; ≈ Θ⁻¹</code>, where <code>Θ</code> is a covariance matrix and <code>L * L&#39;</code> is the approximate precision (inverse covariance) matrix.</p><p>This function uses the sparsity pattern already defined in <code>L</code> and fills in the values using local Cholesky decompositions at each step. The approximation quality depends on the sparsity pattern of <code>L</code>.</p><p><strong>Arguments</strong></p><ul><li><p><code>Θ::AbstractMatrix</code>: Covariance matrix to be inverted approximately</p></li><li><p><code>L::SparseMatrixCSC</code>: Sparse lower-triangular matrix with predefined sparsity pattern. Values will be overwritten.</p></li></ul><p><strong>Details</strong></p><p>The algorithm proceeds column-by-column through <code>L</code>, solving local linear systems using dense Cholesky factorizations on small submatrices of <code>Θ</code>. A small regularization term (<code>1e-6 * I</code>) is added for numerical stability.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.approximate_gmrf_kl"><code>approximate_gmrf_kl</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/kl_cholesky.jl#L5-L30" target="_blank" rel="noreferrer">source</a><!--]--></span></details><h2 id="Supporting-Functions" tabindex="-1">Supporting Functions <a class="header-anchor" href="#Supporting-Functions" aria-label="Permalink to &quot;Supporting Functions {#Supporting-Functions}&quot;">​</a></h2><h3 id="Point-Ordering" tabindex="-1">Point Ordering <a class="header-anchor" href="#Point-Ordering" aria-label="Permalink to &quot;Point Ordering {#Point-Ordering}&quot;">​</a></h3><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.reverse_maximin_ordering" href="#GaussianMarkovRandomFields.reverse_maximin_ordering"><span class="jlbinding">GaussianMarkovRandomFields.reverse_maximin_ordering</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">reverse_maximin_ordering</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; point_tree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> KDTree</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X))</span></span></code></pre></div><p>Compute a reverse maximin ordering of spatial points.</p><p>The reverse maximin ordering selects points greedily to maximize the distance to previously selected points. This creates a hierarchical structure where similar points appear consecutively in the ordering, which is beneficial for sparse Cholesky factorization.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension)</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>point_tree = KDTree(X)</code>: Pre-computed KDTree for efficient nearest neighbor queries</li></ul><p><strong>Returns</strong></p><ul><li><p><code>P::Vector{Int}</code>: Permutation vector (ordering of points)</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li></ul><p><strong>Details</strong></p><p>The algorithm maintains a priority queue of unselected points, ordered by their distance to the nearest selected point. At each step, it selects the point furthest from all previously selected points.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern"><code>reverse_maximin_ordering_and_sparsity_pattern</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/maximin.jl#L6-L33" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern" href="#GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern"><span class="jlbinding">GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">reverse_maximin_ordering_and_sparsity_pattern</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Real</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; lower </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Compute reverse maximin ordering and determine the sparsity pattern for sparse Cholesky factorization.</p><p>This function combines the reverse maximin ordering with sparsity pattern construction based on spatial neighborhoods. The resulting sparsity pattern determines which entries of the Cholesky factor will be nonzero.</p><p><strong>Arguments</strong></p><ul><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension)</p></li><li><p><code>ρ::Real</code>: Neighborhood radius multiplier for sparsity pattern construction</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>lower::Bool = true</code>: If true, return lower triangular pattern; otherwise upper triangular</li></ul><p><strong>Returns</strong></p><ul><li><p><code>S::SparseMatrixCSC</code>: Sparsity pattern matrix (all nonzeros are 0.0, structure only)</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector from reverse maximin ordering</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li></ul><p><strong>Details</strong></p><p>For each point i, the algorithm includes entries in the sparsity pattern for all neighbors within distance <code>ρ × ℓᵢ</code>, where <code>ℓᵢ</code> is the maximin distance for point i. Larger <code>ρ</code> values create denser (and more accurate) approximations.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering"><code>reverse_maximin_ordering</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/maximin.jl#L68-L96" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.sparsity_pattern_from_ordering" href="#GaussianMarkovRandomFields.sparsity_pattern_from_ordering"><span class="jlbinding">GaussianMarkovRandomFields.sparsity_pattern_from_ordering</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sparsity_pattern_from_ordering</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, P</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Vector{Int}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ℓ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Vector{Float64}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Real</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; lower </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, point_tree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> KDTree</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X))</span></span></code></pre></div><p>Construct sparsity pattern for sparse Cholesky factorization from a pre-computed ordering.</p><p>This function allows users who already have a permutation <code>P</code> and maximin distances <code>ℓ</code> (from <code>reverse_maximin_ordering</code> or other sources) to construct the sparsity pattern independently. This is useful when the ordering has been computed separately or when experimenting with different sparsity parameters <code>ρ</code> on the same ordering.</p><p><strong>Arguments</strong></p><ul><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension)</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector (ordering of points)</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li><li><p><code>ρ::Real</code>: Neighborhood radius multiplier for sparsity pattern construction</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>lower::Bool = true</code>: If true, return lower triangular pattern; otherwise upper triangular</p></li><li><p><code>point_tree = KDTree(X)</code>: Pre-computed KDTree for efficient nearest neighbor queries</p></li></ul><p><strong>Returns</strong></p><ul><li><code>S::SparseMatrixCSC</code>: Sparsity pattern matrix (all nonzeros are 0.0, structure only)</li></ul><p><strong>Details</strong></p><p>For each point i, the algorithm includes entries in the sparsity pattern for all neighbors within distance <code>ρ × ℓᵢ</code>, where <code>ℓᵢ</code> is the maximin distance for point i. Larger <code>ρ</code> values create denser (and more accurate) approximations.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering"><code>reverse_maximin_ordering</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern"><code>reverse_maximin_ordering_and_sparsity_pattern</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/maximin.jl#L104-L134" target="_blank" rel="noreferrer">source</a><!--]--></span></details><h3 id="Supernodal-Clustering" tabindex="-1">Supernodal Clustering <a class="header-anchor" href="#Supernodal-Clustering" aria-label="Permalink to &quot;Supernodal Clustering {#Supernodal-Clustering}&quot;">​</a></h3><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.SupernodeClustering" href="#GaussianMarkovRandomFields.SupernodeClustering"><span class="jlbinding">GaussianMarkovRandomFields.SupernodeClustering</span></a> <span class="VPBadge info jlObjectType jlType"><!--[-->Type<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">SupernodeClustering</span></span></code></pre></div><p>Represents a clustering of matrix columns into supernodes for sparse Cholesky factorization.</p><p><strong>Fields</strong></p><ul><li><p><code>column_indices::Vector{Vector{Int}}</code>: For each supernode, the column indices belonging to it</p></li><li><p><code>row_indices::Vector{SortedSet{Int}}</code>: For each supernode, the row indices in its sparsity pattern</p></li></ul><p>Supernodes group columns with similar sparsity patterns to enable more efficient factorization through larger dense linear algebra operations.</p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/supernodes.jl#L5-L16" target="_blank" rel="noreferrer">source</a><!--]--></span></details><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.form_supernodes" href="#GaussianMarkovRandomFields.form_supernodes"><span class="jlbinding">GaussianMarkovRandomFields.form_supernodes</span></a> <span class="VPBadge info jlObjectType jlFunction"><!--[-->Function<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">form_supernodes</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(S</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SparseMatrixCSC</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, P, ℓ; λ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Cluster columns of a sparse matrix into supernodes based on maximin distances.</p><p>Groups columns with similar sparsity patterns and nearby maximin distances into &quot;supernodes&quot; for more efficient sparse Cholesky factorization.</p><p><strong>Arguments</strong></p><ul><li><p><code>S::SparseMatrixCSC</code>: Sparse sparsity pattern matrix</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector from reverse maximin ordering</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>λ::Real = 1.5</code>: Clustering threshold. Columns are grouped if their maximin distances differ by less than this factor. Larger values create larger supernodes.</li></ul><p><strong>Returns</strong></p><ul><li><code>SupernodeClustering</code>: The supernodal clustering structure</li></ul><p><strong>Details</strong></p><p>The algorithm processes columns sequentially in the permuted order. For each unassigned column, it creates a new supernode and assigns all unassigned child columns (in the sparsity pattern) whose maximin distances satisfy <code>ℓ[i] &lt;= λ * ℓ[j]</code>.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.SupernodeClustering"><code>SupernodeClustering</code></a>, <a href="/GaussianMarkovRandomFields.jl/stable/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/supernodes.jl#L25-L52" target="_blank" rel="noreferrer">source</a><!--]--></span></details><p>The <code>form_supernodes</code> function takes the sparsity pattern and maximin ordering and creates a supernodal clustering. This is used internally when <code>λ !== nothing</code>.</p><h3 id="Matrix-Utilities" tabindex="-1">Matrix Utilities <a class="header-anchor" href="#Matrix-Utilities" aria-label="Permalink to &quot;Matrix Utilities {#Matrix-Utilities}&quot;">​</a></h3><details class="jldocstring custom-block" open><summary><a id="GaussianMarkovRandomFields.PermutedMatrix" href="#GaussianMarkovRandomFields.PermutedMatrix"><span class="jlbinding">GaussianMarkovRandomFields.PermutedMatrix</span></a> <span class="VPBadge info jlObjectType jlType"><!--[-->Type<!--]--></span></summary><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PermutedMatrix{T, M </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AbstractMatrix{T}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">} </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AbstractMatrix{T}</span></span></code></pre></div><p>A memory-efficient wrapper that represents a symmetrically permuted matrix without materializing it. For a matrix <code>A</code> and permutation vector <code>p</code>, <code>PermutedMatrix(A, p)</code> represents <code>A[p, p]</code> without forming it explicitly.</p><p>This is particularly useful for accessing elements of permuted matrices in sparse matrix algorithms without the memory overhead of creating a full permuted copy.</p><p><strong>Type Parameters</strong></p><ul><li><p><code>T</code>: Element type of the matrix</p></li><li><p><code>M</code>: Type of the underlying matrix (must be &lt;: AbstractMatrix{T})</p></li></ul><p><strong>Fields</strong></p><ul><li><p><code>matrix::M</code>: The underlying matrix</p></li><li><p><code>perm::Vector{Int}</code>: Permutation vector (must have length equal to matrix dimensions)</p></li></ul><p><strong>Examples</strong></p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">A </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 5</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">7</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> PermutedMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(A, p)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access individual elements (applies permutation to both indices)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access blocks</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Convert to explicit matrix</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">to_matrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(PA) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[p, p]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span></code></pre></div><span class="VPBadge info source-link"><!--[--><a href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/permuted_matrix.jl#L5-L39" target="_blank" rel="noreferrer">source</a><!--]--></span></details><p>The <code>PermutedMatrix</code> wrapper enables efficient access to permuted covariance matrices without materializing the full permuted matrix in memory.</p><h2 id="Performance-Considerations" tabindex="-1">Performance Considerations <a class="header-anchor" href="#Performance-Considerations" aria-label="Permalink to &quot;Performance Considerations {#Performance-Considerations}&quot;">​</a></h2><h3 id="When-to-Use-Supernodal-Factorization" tabindex="-1">When to Use Supernodal Factorization <a class="header-anchor" href="#When-to-Use-Supernodal-Factorization" aria-label="Permalink to &quot;When to Use Supernodal Factorization {#When-to-Use-Supernodal-Factorization}&quot;">​</a></h3><p>The default supernodal factorization (<code>λ=1.5</code>) is recommended for most use cases, as it&#39;s typically faster and more accurate. You should only consider disabling it (<code>λ=nothing</code>) for very small problems (fewer than 100 points), extremely memory-constrained environments, or when debugging or comparing against a reference implementation.</p><h2 id="See-Also" tabindex="-1">See Also <a class="header-anchor" href="#See-Also" aria-label="Permalink to &quot;See Also {#See-Also}&quot;">​</a></h2><ul><li><p><a href="/GaussianMarkovRandomFields.jl/stable/tutorials/kl_approximation#KL-minimizing-Sparse-GMRF-Approximations-to-Gaussian-Processes">KL-minimizing Sparse GMRF Approximations to Gaussian Processes</a> tutorial demonstrates the full workflow with examples</p></li><li><p>[<a href="/GaussianMarkovRandomFields.jl/stable/bibliography#Schaefer2021">3</a>] for the full paper describing these algorithms in detail</p></li></ul></div></div></main><footer class="VPDocFooter" data-v-83890dd9 data-v-4f9813fa><!--[--><!--]--><div class="edit-info" data-v-4f9813fa><div class="edit-link" data-v-4f9813fa><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/timweiland/GaussianMarkovRandomFields.jl/edit/main/docs/src/reference/kl_approximation.md" target="_blank" rel="noreferrer" data-v-4f9813fa><!--[--><span class="vpi-square-pen edit-link-icon" data-v-4f9813fa></span> Edit this page<!--]--></a></div><!----></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-4f9813fa><span class="visually-hidden" id="doc-footer-aria-label" data-v-4f9813fa>Pager</span><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link prev" href="/GaussianMarkovRandomFields.jl/stable/reference/autodiff" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Previous page</span><span class="title" data-v-4f9813fa>Automatic Differentiation</span><!--]--></a></div><div class="pager" data-v-4f9813fa><a class="VPLink link pager-link next" href="/GaussianMarkovRandomFields.jl/stable/reference/spdes" data-v-4f9813fa><!--[--><span class="desc" data-v-4f9813fa>Next page</span><span class="title" data-v-4f9813fa>SPDEs</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-a9a9e638 data-v-c970a860><div class="container" data-v-c970a860><p class="message" data-v-c970a860>Made with <a href="https://luxdl.github.io/DocumenterVitepress.jl/dev/" target="_blank"><strong>DocumenterVitepress.jl</strong></a><br></p><p class="copyright" data-v-c970a860>© Copyright 2025.</p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"bibliography.md\":\"DaQLfHqs\",\"dev-docs_discretizations.md\":\"CM5WgUjL\",\"dev-docs_index.md\":\"Bw7mUut6\",\"dev-docs_solvers.md\":\"C02KqV88\",\"dev-docs_spdes.md\":\"CbLWNW6g\",\"index.md\":\"3i60a6i4\",\"reference_autodiff.md\":\"BL4ik9ay\",\"reference_autoregressive.md\":\"BbEUHpuE\",\"reference_discretizations.md\":\"B8AeXM4O\",\"reference_formula.md\":\"D8U-1OMP\",\"reference_gaussian_approximation.md\":\"BdNw5XwO\",\"reference_gmrfs.md\":\"Cua5dl6K\",\"reference_hard_constraints.md\":\"BYnv3SfL\",\"reference_index.md\":\"Dyltidvl\",\"reference_kl_approximation.md\":\"BC4PnrO1\",\"reference_latent_models.md\":\"CejXGBwl\",\"reference_linear_maps.md\":\"JljSEOok\",\"reference_meshes.md\":\"DLs9Gpn_\",\"reference_observation_models.md\":\"BaSxKqkf\",\"reference_plotting.md\":\"CJ5vKPO5\",\"reference_preconditioners.md\":\"BM22sdYp\",\"reference_solvers.md\":\"BkhOWXP0\",\"reference_spatial_utils.md\":\"DHT6zRBD\",\"reference_spdes.md\":\"Dkod1vwN\",\"tutorials_automatic_differentiation.md\":\"CF8IibFj\",\"tutorials_autoregressive_models.md\":\"2aVtQAXq\",\"tutorials_bernoulli_spatial_classification.md\":\"-uPjdcuE\",\"tutorials_boundary_conditions.md\":\"DnAYeTmk\",\"tutorials_bym_scotland_lip_cancer.md\":\"DTLm4kPY\",\"tutorials_index.md\":\"D_n1GDoZ\",\"tutorials_kl_approximation.md\":\"wtuwyPAu\",\"tutorials_spatial_modelling_spdes.md\":\"E0IP5BfC\",\"tutorials_spatiotemporal_modelling.md\":\"aKv-vXUX\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"GMRFs.jl\",\"description\":\"Documentation for GaussianMarkovRandomFields.jl\",\"base\":\"/GaussianMarkovRandomFields.jl/stable/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"outline\":\"deep\",\"logo\":{\"src\":\"/logo.svg\",\"width\":24,\"height\":24},\"search\":{\"provider\":\"local\",\"options\":{\"detailedView\":true}},\"nav\":[{\"text\":\"Home\",\"link\":\"/index\"},{\"text\":\"Tutorials\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/index\"},{\"text\":\"Building autoregressive models\",\"link\":\"/tutorials/autoregressive_models\"},{\"text\":\"Spatial Modelling with SPDEs\",\"link\":\"/tutorials/spatial_modelling_spdes\"},{\"text\":\"Spatiotemporal Modelling with SPDEs\",\"link\":\"/tutorials/spatiotemporal_modelling\"},{\"text\":\"Boundary Conditions for SPDEs\",\"link\":\"/tutorials/boundary_conditions\"},{\"text\":\"Bernoulli Spatial Classification with a Matérn Field\",\"link\":\"/tutorials/bernoulli_spatial_classification\"},{\"text\":\"Advanced GMRF modelling for disease mapping\",\"link\":\"/tutorials/bym_scotland_lip_cancer\"},{\"text\":\"KL-minimizing Sparse GMRF Approximations to Gaussian Processes\",\"link\":\"/tutorials/kl_approximation\"},{\"text\":\"Automatic Differentiation for GMRF Hyperparameters\",\"link\":\"/tutorials/automatic_differentiation\"}]},{\"text\":\"API Reference\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/index\"},{\"text\":\"GMRFs\",\"link\":\"/reference/gmrfs\"},{\"text\":\"Latent Models\",\"link\":\"/reference/latent_models\"},{\"text\":\"Observation Models\",\"link\":\"/reference/observation_models\"},{\"text\":\"Gaussian Approximation\",\"link\":\"/reference/gaussian_approximation\"},{\"text\":\"Hard Constraints\",\"link\":\"/reference/hard_constraints\"},{\"text\":\"Automatic Differentiation\",\"link\":\"/reference/autodiff\"},{\"text\":\"KL Approximations\",\"link\":\"/reference/kl_approximation\"},{\"text\":\"SPDEs\",\"link\":\"/reference/spdes\"},{\"text\":\"Discretizations\",\"link\":\"/reference/discretizations\"},{\"text\":\"Meshes\",\"link\":\"/reference/meshes\"},{\"text\":\"Plotting\",\"link\":\"/reference/plotting\"},{\"text\":\"Solvers\",\"link\":\"/reference/solvers\"},{\"text\":\"Autoregressive Models\",\"link\":\"/reference/autoregressive\"},{\"text\":\"Linear maps\",\"link\":\"/reference/linear_maps\"},{\"text\":\"Preconditioners\",\"link\":\"/reference/preconditioners\"}]},{\"text\":\"Bibliography\",\"link\":\"/bibliography\"},{\"text\":\"Developer Documentation\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/dev-docs/index\"},{\"text\":\"Solvers\",\"link\":\"/dev-docs/solvers\"},{\"text\":\"SPDEs\",\"link\":\"/dev-docs/spdes\"},{\"text\":\"Discretizations\",\"link\":\"/dev-docs/discretizations\"}]},{\"component\":\"VersionPicker\"}],\"sidebar\":[{\"text\":\"Home\",\"link\":\"/index\"},{\"text\":\"Tutorials\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/tutorials/index\"},{\"text\":\"Building autoregressive models\",\"link\":\"/tutorials/autoregressive_models\"},{\"text\":\"Spatial Modelling with SPDEs\",\"link\":\"/tutorials/spatial_modelling_spdes\"},{\"text\":\"Spatiotemporal Modelling with SPDEs\",\"link\":\"/tutorials/spatiotemporal_modelling\"},{\"text\":\"Boundary Conditions for SPDEs\",\"link\":\"/tutorials/boundary_conditions\"},{\"text\":\"Bernoulli Spatial Classification with a Matérn Field\",\"link\":\"/tutorials/bernoulli_spatial_classification\"},{\"text\":\"Advanced GMRF modelling for disease mapping\",\"link\":\"/tutorials/bym_scotland_lip_cancer\"},{\"text\":\"KL-minimizing Sparse GMRF Approximations to Gaussian Processes\",\"link\":\"/tutorials/kl_approximation\"},{\"text\":\"Automatic Differentiation for GMRF Hyperparameters\",\"link\":\"/tutorials/automatic_differentiation\"}]},{\"text\":\"API Reference\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/reference/index\"},{\"text\":\"GMRFs\",\"link\":\"/reference/gmrfs\"},{\"text\":\"Latent Models\",\"link\":\"/reference/latent_models\"},{\"text\":\"Observation Models\",\"link\":\"/reference/observation_models\"},{\"text\":\"Gaussian Approximation\",\"link\":\"/reference/gaussian_approximation\"},{\"text\":\"Hard Constraints\",\"link\":\"/reference/hard_constraints\"},{\"text\":\"Automatic Differentiation\",\"link\":\"/reference/autodiff\"},{\"text\":\"KL Approximations\",\"link\":\"/reference/kl_approximation\"},{\"text\":\"SPDEs\",\"link\":\"/reference/spdes\"},{\"text\":\"Discretizations\",\"link\":\"/reference/discretizations\"},{\"text\":\"Meshes\",\"link\":\"/reference/meshes\"},{\"text\":\"Plotting\",\"link\":\"/reference/plotting\"},{\"text\":\"Solvers\",\"link\":\"/reference/solvers\"},{\"text\":\"Autoregressive Models\",\"link\":\"/reference/autoregressive\"},{\"text\":\"Linear maps\",\"link\":\"/reference/linear_maps\"},{\"text\":\"Preconditioners\",\"link\":\"/reference/preconditioners\"}]},{\"text\":\"Bibliography\",\"link\":\"/bibliography\"},{\"text\":\"Developer Documentation\",\"collapsed\":false,\"items\":[{\"text\":\"Overview\",\"link\":\"/dev-docs/index\"},{\"text\":\"Solvers\",\"link\":\"/dev-docs/solvers\"},{\"text\":\"SPDEs\",\"link\":\"/dev-docs/spdes\"},{\"text\":\"Discretizations\",\"link\":\"/dev-docs/discretizations\"}]}],\"editLink\":{\"pattern\":\"https://github.com/timweiland/GaussianMarkovRandomFields.jl/edit/main/docs/src/:path\"},\"socialLinks\":[{\"icon\":\"github\",\"link\":\"https://github.com/timweiland/GaussianMarkovRandomFields.jl\"}],\"footer\":{\"message\":\"Made with <a href=\\\"https://luxdl.github.io/DocumenterVitepress.jl/dev/\\\" target=\\\"_blank\\\"><strong>DocumenterVitepress.jl</strong></a><br>\",\"copyright\":\"© Copyright 2025.\"}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":true}");</script>
    
  </body>
</html>