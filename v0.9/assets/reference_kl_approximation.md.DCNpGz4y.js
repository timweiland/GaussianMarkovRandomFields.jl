import{_ as l,C as o,c as p,o as d,aA as n,j as s,G as e,a as t,w as r}from"./chunks/framework.D1ZhhpGH.js";const T=JSON.parse('{"title":"KL-minimizing Sparse GP Approximations","description":"","frontmatter":{},"headers":[],"relativePath":"reference/kl_approximation.md","filePath":"reference/kl_approximation.md","lastUpdated":null}'),h={name:"reference/kl_approximation.md"},k={class:"jldocstring custom-block",open:""},c={class:"jldocstring custom-block",open:""},u={class:"jldocstring custom-block",open:""},g={class:"jldocstring custom-block",open:""},m={class:"jldocstring custom-block",open:""},y={class:"jldocstring custom-block",open:""},E={class:"jldocstring custom-block",open:""},F={class:"jldocstring custom-block",open:""},f={class:"jldocstring custom-block",open:""};function C(_,i,x,v,b,A){const a=o("Badge");return d(),p("div",null,[i[36]||(i[36]=n('<h1 id="KL-minimizing-Sparse-GP-Approximations" tabindex="-1">KL-minimizing Sparse GP Approximations <a class="header-anchor" href="#KL-minimizing-Sparse-GP-Approximations" aria-label="Permalink to &quot;KL-minimizing Sparse GP Approximations {#KL-minimizing-Sparse-GP-Approximations}&quot;">​</a></h1><p>Sparse GMRF approximations to Gaussian processes defined by kernel (covariance) matrices using KL-divergence minimizing sparse Cholesky factorization.</p><p>These functions enable efficient large-scale GP inference by approximating a dense kernel matrix with a sparse precision matrix using spatially-informed Cholesky factorization that minimizes the Kullback-Leibler divergence.</p><h2 id="Overview" tabindex="-1">Overview <a class="header-anchor" href="#Overview" aria-label="Permalink to &quot;Overview {#Overview}&quot;">​</a></h2><p>The KL-divergence minimizing sparse Cholesky approximation constructs a sparse GMRF from a kernel matrix through a four-stage algorithm that exploits spatial structure to determine which precision matrix entries can be safely set to zero.</p><h3 id="1.-Reverse-Maximin-Ordering" tabindex="-1">1. Reverse Maximin Ordering <a class="header-anchor" href="#1.-Reverse-Maximin-Ordering" aria-label="Permalink to &quot;1. Reverse Maximin Ordering {#1.-Reverse-Maximin-Ordering}&quot;">​</a></h3><p>The algorithm begins by computing a reverse maximin ordering of the input points. This ordering selects points greedily to maximize the distance to previously selected points, creating a natural hierarchical structure where similar points tend to appear consecutively. The result is a permutation vector <code>P</code> that reorders the points for optimal sparsity.</p><h3 id="2.-Sparsity-Pattern-Construction" tabindex="-1">2. Sparsity Pattern Construction <a class="header-anchor" href="#2.-Sparsity-Pattern-Construction" aria-label="Permalink to &quot;2. Sparsity Pattern Construction {#2.-Sparsity-Pattern-Construction}&quot;">​</a></h3><p>Based on the ordering and spatial locations, the algorithm determines a sparsity pattern using a neighborhood radius <code>ρ × ℓᵢ</code>, where <code>ℓᵢ</code> is the maximin distance for point <code>i</code>. This radius defines which matrix entries will be nonzero. Larger <code>ρ</code> values create denser (and more accurate) approximations at the cost of increased computational expense.</p><h3 id="3.-Supernodal-Clustering-Optional,-Default" tabindex="-1">3. Supernodal Clustering (Optional, Default) <a class="header-anchor" href="#3.-Supernodal-Clustering-Optional,-Default" aria-label="Permalink to &quot;3. Supernodal Clustering (Optional, Default) {#3.-Supernodal-Clustering-Optional,-Default}&quot;">​</a></h3><p>By default, the algorithm uses supernodal clustering to group columns with similar sparsity patterns into &quot;supernodes&quot;. Rather than solving many small linear systems (one per column), the algorithm solves fewer but larger systems (one per supernode). This tends to be much more efficient since larger matrix operations can take advantage of optimized BLAS routines.</p><p>The clustering parameter <code>λ</code> (typically 1.5) controls the similarity threshold: columns are grouped together if their maximin distances differ by less than this factor.</p><h3 id="4.-Cholesky-Factorization" tabindex="-1">4. Cholesky Factorization <a class="header-anchor" href="#4.-Cholesky-Factorization" aria-label="Permalink to &quot;4. Cholesky Factorization {#4.-Cholesky-Factorization}&quot;">​</a></h3><p>The algorithm fills in the sparse Cholesky factor <code>L</code> such that <code>L * L&#39; ≈ (PKP&#39;)⁻¹</code>, where <code>K</code> is the covariance matrix. For each supernode (or individual column when not using supernodes), the algorithm extracts the relevant submatrix of the covariance, solves a small dense Cholesky problem, and fills in the corresponding entries of <code>L</code>. The result is a GMRF with sparse precision matrix <code>Q ≈ K⁻¹</code> that enables efficient inference.</p><h2 id="Algorithm-Parameters" tabindex="-1">Algorithm Parameters <a class="header-anchor" href="#Algorithm-Parameters" aria-label="Permalink to &quot;Algorithm Parameters {#Algorithm-Parameters}&quot;">​</a></h2><p>The algorithm has two main tuning parameters:</p><p>The sparsity radius parameter <code>ρ</code> (default: 2.0) controls the neighborhood size for determining sparsity. Larger values create denser approximations with better accuracy but higher computational cost. Typical values range from 1.5 to 3.0, with 2.0-2.5 being a good balanced choice for most applications.</p><p>The supernodal clustering threshold <code>λ</code> (default: 1.5) controls how columns are grouped into supernodes. Setting it to <code>nothing</code> disables supernodal clustering entirely, which can be useful for very small problems or debugging. Higher values create larger supernodes, which can improve performance if the problem structure is favorable.</p><h2 id="Main-Functions" tabindex="-1">Main Functions <a class="header-anchor" href="#Main-Functions" aria-label="Permalink to &quot;Main Functions {#Main-Functions}&quot;">​</a></h2>',19)),s("details",k,[s("summary",null,[i[0]||(i[0]=s("a",{id:"GaussianMarkovRandomFields.approximate_gmrf_kl",href:"#GaussianMarkovRandomFields.approximate_gmrf_kl"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.approximate_gmrf_kl")],-1)),i[1]||(i[1]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[3]||(i[3]=n(`<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">approximate_gmrf_kl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(kernel_mat</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; ρ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, λ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, alg </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> LinearSolve</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">CHOLMODFactorization</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">())</span></span></code></pre></div><p>Construct a sparse GMRF approximation from a kernel (covariance) matrix.</p><p>Given a kernel matrix <code>K</code> (covariance matrix) obtained by evaluating a kernel function at input points <code>X</code>, construct a sparse Gaussian Markov Random Field (GMRF) that approximates the corresponding Gaussian process.</p><p><strong>Arguments</strong></p><ul><li><p><code>kernel_mat::AbstractMatrix</code>: Kernel (covariance) matrix</p></li><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension, n is number of points)</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>ρ::Real = 2.0</code>: Sparsity pattern radius parameter. Larger values create denser, more accurate approximations. Typical range: [1.5, 3.0].</p></li><li><p><code>λ::Union{Real,Nothing} = 1.5</code>: Supernodal clustering parameter. If <code>nothing</code>, uses standard column-by-column factorization. If a number, uses supernodal clustering (typically 1.5). Supernodal factorization is usually faster due to improved cache efficiency.</p></li><li><p><code>alg = LinearSolve.CHOLMODFactorization()</code>: LinearSolve algorithm for the resulting GMRF</p></li></ul><p><strong>Returns</strong></p><ul><li><code>::GMRF</code>: A sparse GMRF with zero mean and sparse precision matrix approximating <code>K⁻¹</code></li></ul><p><strong>Examples</strong></p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">using</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KernelFunctions, GaussianMarkovRandomFields</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create spatial grid</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">X </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> hcat</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">([[x, y] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Define kernel and compute kernel matrix</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kernel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> with_lengthscale</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Matern32Kernel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(), </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">K </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> kernelmatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(kernel, X, obsdim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Create sparse GMRF approximation (uses supernodal by default)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gmrf </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> approximate_gmrf_kl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(K, X; ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Use non-supernodal version</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">gmrf_nonsupernodal </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> approximate_gmrf_kl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(K, X; ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, λ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">nothing</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Use for inference</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">posterior </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> linear_condition</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(gmrf; A</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">A, Q_ϵ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Q_ϵ, y</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y)</span></span></code></pre></div><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/gmrfs#GaussianMarkovRandomFields.GMRF"><code>GMRF</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/gmrfs#GaussianMarkovRandomFields.linear_condition"><code>linear_condition</code></a></p>`,13)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[2]||(i[2]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/kl_cholesky.jl#L156-L202",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),s("details",c,[s("summary",null,[i[4]||(i[4]=s("a",{id:"GaussianMarkovRandomFields.sparse_approximate_cholesky",href:"#GaussianMarkovRandomFields.sparse_approximate_cholesky"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.sparse_approximate_cholesky")],-1)),i[5]||(i[5]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[7]||(i[7]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sparse_approximate_cholesky</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Θ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; ρ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, λ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Compute sparse approximate Cholesky factorization with automatic sparsity pattern.</p><p>Given a covariance matrix <code>Θ</code> and spatial input points <code>X</code>, compute a sparse approximate Cholesky factor <code>L</code> and permutation <code>P</code> such that <code>L * L&#39; ≈ (Θ[P, P])⁻¹</code>.</p><p><strong>Arguments</strong></p><ul><li><p><code>Θ::AbstractMatrix</code>: Covariance matrix to be inverted approximately</p></li><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension, n is number of points)</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>ρ::Real = 2.0</code>: Sparsity pattern radius parameter. Controls the neighborhood size used to determine sparsity. Larger values create denser (more accurate) approximations. Typical values are in the range [1.5, 3.0].</p></li><li><p><code>λ::Union{Real,Nothing} = 1.5</code>: Supernodal clustering parameter. If <code>nothing</code>, uses standard column-by-column factorization. If a number, uses supernodal clustering with the given threshold (typically 1.5). Supernodal factorization groups nearby columns together for improved cache efficiency and is usually faster.</p></li></ul><p><strong>Returns</strong></p><ul><li><p><code>L::SparseMatrixCSC</code>: Lower-triangular sparse Cholesky factor in permuted coordinates</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector from the reverse maximin ordering</p></li></ul><p><strong>Details</strong></p><p>The permutation <code>P</code> reorders the points to achieve better sparsity. The returned factor <code>L</code> satisfies <code>L * L&#39; ≈ (Θ[P, P])⁻¹</code>, or equivalently <code>(L * L&#39;)[invperm(P), invperm(P)] ≈ Θ⁻¹</code>.</p><p>When <code>λ !== nothing</code>, the algorithm uses supernodal clustering to group columns with similar sparsity patterns, solving larger dense systems less frequently rather than many small systems. This typically improves performance through better cache locality.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky!"><code>sparse_approximate_cholesky!</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.approximate_gmrf_kl"><code>approximate_gmrf_kl</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering"><code>reverse_maximin_ordering</code></a></p>',14)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[6]||(i[6]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/kl_cholesky.jl#L104-L139",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),s("details",u,[s("summary",null,[i[8]||(i[8]=s("a",{id:"GaussianMarkovRandomFields.sparse_approximate_cholesky!",href:"#GaussianMarkovRandomFields.sparse_approximate_cholesky!"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.sparse_approximate_cholesky!")],-1)),i[9]||(i[9]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[11]||(i[11]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sparse_approximate_cholesky!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(Θ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, L</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SparseMatrixCSC</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>In-place computation of sparse approximate Cholesky factorization.</p><p>Fill the nonzero values of the lower-triangular sparse matrix <code>L</code> such that <code>L * L&#39; ≈ Θ⁻¹</code>, where <code>Θ</code> is a covariance matrix and <code>L * L&#39;</code> is the approximate precision (inverse covariance) matrix.</p><p>This function uses the sparsity pattern already defined in <code>L</code> and fills in the values using local Cholesky decompositions at each step. The approximation quality depends on the sparsity pattern of <code>L</code>.</p><p><strong>Arguments</strong></p><ul><li><p><code>Θ::AbstractMatrix</code>: Covariance matrix to be inverted approximately</p></li><li><p><code>L::SparseMatrixCSC</code>: Sparse lower-triangular matrix with predefined sparsity pattern. Values will be overwritten.</p></li></ul><p><strong>Details</strong></p><p>The algorithm proceeds column-by-column through <code>L</code>, solving local linear systems using dense Cholesky factorizations on small submatrices of <code>Θ</code>. A small regularization term (<code>1e-6 * I</code>) is added for numerical stability.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.approximate_gmrf_kl"><code>approximate_gmrf_kl</code></a></p>',10)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[10]||(i[10]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/kl_cholesky.jl#L5-L30",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),i[37]||(i[37]=s("h2",{id:"Supporting-Functions",tabindex:"-1"},[t("Supporting Functions "),s("a",{class:"header-anchor",href:"#Supporting-Functions","aria-label":'Permalink to "Supporting Functions {#Supporting-Functions}"'},"​")],-1)),i[38]||(i[38]=s("h3",{id:"Point-Ordering",tabindex:"-1"},[t("Point Ordering "),s("a",{class:"header-anchor",href:"#Point-Ordering","aria-label":'Permalink to "Point Ordering {#Point-Ordering}"'},"​")],-1)),s("details",g,[s("summary",null,[i[12]||(i[12]=s("a",{id:"GaussianMarkovRandomFields.reverse_maximin_ordering",href:"#GaussianMarkovRandomFields.reverse_maximin_ordering"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.reverse_maximin_ordering")],-1)),i[13]||(i[13]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[15]||(i[15]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">reverse_maximin_ordering</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; point_tree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> KDTree</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X))</span></span></code></pre></div><p>Compute a reverse maximin ordering of spatial points.</p><p>The reverse maximin ordering selects points greedily to maximize the distance to previously selected points. This creates a hierarchical structure where similar points appear consecutively in the ordering, which is beneficial for sparse Cholesky factorization.</p><p><strong>Arguments</strong></p><ul><li><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension)</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>point_tree = KDTree(X)</code>: Pre-computed KDTree for efficient nearest neighbor queries</li></ul><p><strong>Returns</strong></p><ul><li><p><code>P::Vector{Int}</code>: Permutation vector (ordering of points)</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li></ul><p><strong>Details</strong></p><p>The algorithm maintains a priority queue of unselected points, ordered by their distance to the nearest selected point. At each step, it selects the point furthest from all previously selected points.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern"><code>reverse_maximin_ordering_and_sparsity_pattern</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p>',13)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[14]||(i[14]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/maximin.jl#L6-L33",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),s("details",m,[s("summary",null,[i[16]||(i[16]=s("a",{id:"GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern",href:"#GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern")],-1)),i[17]||(i[17]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[19]||(i[19]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">reverse_maximin_ordering_and_sparsity_pattern</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Real</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; lower </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Compute reverse maximin ordering and determine the sparsity pattern for sparse Cholesky factorization.</p><p>This function combines the reverse maximin ordering with sparsity pattern construction based on spatial neighborhoods. The resulting sparsity pattern determines which entries of the Cholesky factor will be nonzero.</p><p><strong>Arguments</strong></p><ul><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension)</p></li><li><p><code>ρ::Real</code>: Neighborhood radius multiplier for sparsity pattern construction</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>lower::Bool = true</code>: If true, return lower triangular pattern; otherwise upper triangular</li></ul><p><strong>Returns</strong></p><ul><li><p><code>S::SparseMatrixCSC</code>: Sparsity pattern matrix (all nonzeros are 0.0, structure only)</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector from reverse maximin ordering</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li></ul><p><strong>Details</strong></p><p>For each point i, the algorithm includes entries in the sparsity pattern for all neighbors within distance <code>ρ × ℓᵢ</code>, where <code>ℓᵢ</code> is the maximin distance for point i. Larger <code>ρ</code> values create denser (and more accurate) approximations.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering"><code>reverse_maximin_ordering</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p>',13)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[18]||(i[18]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/maximin.jl#L68-L96",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),s("details",y,[s("summary",null,[i[20]||(i[20]=s("a",{id:"GaussianMarkovRandomFields.sparsity_pattern_from_ordering",href:"#GaussianMarkovRandomFields.sparsity_pattern_from_ordering"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.sparsity_pattern_from_ordering")],-1)),i[21]||(i[21]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[23]||(i[23]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">sparsity_pattern_from_ordering</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">AbstractMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, P</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Vector{Int}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ℓ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Vector{Float64}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, ρ</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">Real</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; lower </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, point_tree </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> KDTree</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(X))</span></span></code></pre></div><p>Construct sparsity pattern for sparse Cholesky factorization from a pre-computed ordering.</p><p>This function allows users who already have a permutation <code>P</code> and maximin distances <code>ℓ</code> (from <code>reverse_maximin_ordering</code> or other sources) to construct the sparsity pattern independently. This is useful when the ordering has been computed separately or when experimenting with different sparsity parameters <code>ρ</code> on the same ordering.</p><p><strong>Arguments</strong></p><ul><li><p><code>X::AbstractMatrix</code>: Input point locations (d × n matrix where d is spatial dimension)</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector (ordering of points)</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li><li><p><code>ρ::Real</code>: Neighborhood radius multiplier for sparsity pattern construction</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><p><code>lower::Bool = true</code>: If true, return lower triangular pattern; otherwise upper triangular</p></li><li><p><code>point_tree = KDTree(X)</code>: Pre-computed KDTree for efficient nearest neighbor queries</p></li></ul><p><strong>Returns</strong></p><ul><li><code>S::SparseMatrixCSC</code>: Sparsity pattern matrix (all nonzeros are 0.0, structure only)</li></ul><p><strong>Details</strong></p><p>For each point i, the algorithm includes entries in the sparsity pattern for all neighbors within distance <code>ρ × ℓᵢ</code>, where <code>ℓᵢ</code> is the maximin distance for point i. Larger <code>ρ</code> values create denser (and more accurate) approximations.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering"><code>reverse_maximin_ordering</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.reverse_maximin_ordering_and_sparsity_pattern"><code>reverse_maximin_ordering_and_sparsity_pattern</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p>',13)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[22]||(i[22]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/maximin.jl#L104-L134",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),i[39]||(i[39]=s("h3",{id:"Supernodal-Clustering",tabindex:"-1"},[t("Supernodal Clustering "),s("a",{class:"header-anchor",href:"#Supernodal-Clustering","aria-label":'Permalink to "Supernodal Clustering {#Supernodal-Clustering}"'},"​")],-1)),s("details",E,[s("summary",null,[i[24]||(i[24]=s("a",{id:"GaussianMarkovRandomFields.SupernodeClustering",href:"#GaussianMarkovRandomFields.SupernodeClustering"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.SupernodeClustering")],-1)),i[25]||(i[25]=t()),e(a,{type:"info",class:"jlObjectType jlType",text:"Type"})]),i[27]||(i[27]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">SupernodeClustering</span></span></code></pre></div><p>Represents a clustering of matrix columns into supernodes for sparse Cholesky factorization.</p><p><strong>Fields</strong></p><ul><li><p><code>column_indices::Vector{Vector{Int}}</code>: For each supernode, the column indices belonging to it</p></li><li><p><code>row_indices::Vector{SortedSet{Int}}</code>: For each supernode, the row indices in its sparsity pattern</p></li></ul><p>Supernodes group columns with similar sparsity patterns to enable more efficient factorization through larger dense linear algebra operations.</p>',5)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[26]||(i[26]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/supernodes.jl#L5-L16",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),s("details",F,[s("summary",null,[i[28]||(i[28]=s("a",{id:"GaussianMarkovRandomFields.form_supernodes",href:"#GaussianMarkovRandomFields.form_supernodes"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.form_supernodes")],-1)),i[29]||(i[29]=t()),e(a,{type:"info",class:"jlObjectType jlFunction",text:"Function"})]),i[31]||(i[31]=n('<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">form_supernodes</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(S</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">::</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">SparseMatrixCSC</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, P, ℓ; λ </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>Cluster columns of a sparse matrix into supernodes based on maximin distances.</p><p>Groups columns with similar sparsity patterns and nearby maximin distances into &quot;supernodes&quot; for more efficient sparse Cholesky factorization.</p><p><strong>Arguments</strong></p><ul><li><p><code>S::SparseMatrixCSC</code>: Sparse sparsity pattern matrix</p></li><li><p><code>P::Vector{Int}</code>: Permutation vector from reverse maximin ordering</p></li><li><p><code>ℓ::Vector{Float64}</code>: Maximin distances for each point</p></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>λ::Real = 1.5</code>: Clustering threshold. Columns are grouped if their maximin distances differ by less than this factor. Larger values create larger supernodes.</li></ul><p><strong>Returns</strong></p><ul><li><code>SupernodeClustering</code>: The supernodal clustering structure</li></ul><p><strong>Details</strong></p><p>The algorithm processes columns sequentially in the permuted order. For each unassigned column, it creates a new supernode and assigns all unassigned child columns (in the sparsity pattern) whose maximin distances satisfy <code>ℓ[i] &lt;= λ * ℓ[j]</code>.</p><p><strong>See also</strong></p><p><a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.SupernodeClustering"><code>SupernodeClustering</code></a>, <a href="/GaussianMarkovRandomFields.jl/v0.9/reference/kl_approximation#GaussianMarkovRandomFields.sparse_approximate_cholesky"><code>sparse_approximate_cholesky</code></a></p>',13)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[30]||(i[30]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/supernodes.jl#L25-L52",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),i[40]||(i[40]=s("p",null,[t("The "),s("code",null,"form_supernodes"),t(" function takes the sparsity pattern and maximin ordering and creates a supernodal clustering. This is used internally when "),s("code",null,"λ !== nothing"),t(".")],-1)),i[41]||(i[41]=s("h3",{id:"Matrix-Utilities",tabindex:"-1"},[t("Matrix Utilities "),s("a",{class:"header-anchor",href:"#Matrix-Utilities","aria-label":'Permalink to "Matrix Utilities {#Matrix-Utilities}"'},"​")],-1)),s("details",f,[s("summary",null,[i[32]||(i[32]=s("a",{id:"GaussianMarkovRandomFields.PermutedMatrix",href:"#GaussianMarkovRandomFields.PermutedMatrix"},[s("span",{class:"jlbinding"},"GaussianMarkovRandomFields.PermutedMatrix")],-1)),i[33]||(i[33]=t()),e(a,{type:"info",class:"jlObjectType jlType",text:"Type"})]),i[35]||(i[35]=n(`<div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PermutedMatrix{T, M </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AbstractMatrix{T}</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">} </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> AbstractMatrix{T}</span></span></code></pre></div><p>A memory-efficient wrapper that represents a symmetrically permuted matrix without materializing it. For a matrix <code>A</code> and permutation vector <code>p</code>, <code>PermutedMatrix(A, p)</code> represents <code>A[p, p]</code> without forming it explicitly.</p><p>This is particularly useful for accessing elements of permuted matrices in sparse matrix algorithms without the memory overhead of creating a full permuted copy.</p><p><strong>Type Parameters</strong></p><ul><li><p><code>T</code>: Element type of the matrix</p></li><li><p><code>M</code>: Type of the underlying matrix (must be &lt;: AbstractMatrix{T})</p></li></ul><p><strong>Fields</strong></p><ul><li><p><code>matrix::M</code>: The underlying matrix</p></li><li><p><code>perm::Vector{Int}</code>: Permutation vector (must have length equal to matrix dimensions)</p></li></ul><p><strong>Examples</strong></p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">A </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 2</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 5</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">7</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">p </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> PermutedMatrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(A, p)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access individual elements (applies permutation to both indices)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Access blocks</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">PA[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Convert to explicit matrix</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">to_matrix</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(PA) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> A[p, p]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># true</span></span></code></pre></div>`,9)),e(a,{type:"info",class:"source-link",text:"source"},{default:r(()=>[...i[34]||(i[34]=[s("a",{href:"https://github.com/timweiland/GaussianMarkovRandomFields.jl/blob/b58d7cee91b1f28af7211f81ee46d597fac53851/src/kl_cholesky/permuted_matrix.jl#L5-L39",target:"_blank",rel:"noreferrer"},"source",-1)])]),_:1})]),i[42]||(i[42]=n('<p>The <code>PermutedMatrix</code> wrapper enables efficient access to permuted covariance matrices without materializing the full permuted matrix in memory.</p><h2 id="Performance-Considerations" tabindex="-1">Performance Considerations <a class="header-anchor" href="#Performance-Considerations" aria-label="Permalink to &quot;Performance Considerations {#Performance-Considerations}&quot;">​</a></h2><h3 id="When-to-Use-Supernodal-Factorization" tabindex="-1">When to Use Supernodal Factorization <a class="header-anchor" href="#When-to-Use-Supernodal-Factorization" aria-label="Permalink to &quot;When to Use Supernodal Factorization {#When-to-Use-Supernodal-Factorization}&quot;">​</a></h3><p>The default supernodal factorization (<code>λ=1.5</code>) is recommended for most use cases, as it&#39;s typically faster and more accurate. You should only consider disabling it (<code>λ=nothing</code>) for very small problems (fewer than 100 points), extremely memory-constrained environments, or when debugging or comparing against a reference implementation.</p><h2 id="See-Also" tabindex="-1">See Also <a class="header-anchor" href="#See-Also" aria-label="Permalink to &quot;See Also {#See-Also}&quot;">​</a></h2><ul><li><p><a href="/GaussianMarkovRandomFields.jl/v0.9/tutorials/kl_approximation#KL-minimizing-Sparse-GMRF-Approximations-to-Gaussian-Processes">KL-minimizing Sparse GMRF Approximations to Gaussian Processes</a> tutorial demonstrates the full workflow with examples</p></li><li><p>[<a href="/GaussianMarkovRandomFields.jl/v0.9/bibliography#Schaefer2021">3</a>] for the full paper describing these algorithms in detail</p></li></ul>',6))])}const S=l(h,[["render",C]]);export{T as __pageData,S as default};
